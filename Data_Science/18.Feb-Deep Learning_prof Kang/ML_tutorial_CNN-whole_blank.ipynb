{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python을 이용해 CNN 구현하기\n",
    "\n",
    "#### 2018-02-01 오상신"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 들어가기 전에\n",
    "---\n",
    "\n",
    "#### 이 노트북에서 구현하는 코드는 [출처](https://tensorflow.blog/5-텐서플로우-다중-레이어-뉴럴-네트워크-first-contact-with-tensorflow/)를 참고했습니다.\n",
    "\n",
    "#### 코드\n",
    "- 이 노트북에서 구현하고자 하는 것은 **Convolutional Neural Network**를 이용해 MNIST 데이터를 분류하는 코드입니다.\n",
    "- **Tensorflow**를 이용해 구현하며, 따라서 backpropagation은 직접 구현하지 않습니다.\n",
    "\n",
    "#### Jupyter Notebook\n",
    "- 이 노트북에서 직접 코드를 실행시킬 수 있으며, 단축키는 **shift + enter**입니다.\n",
    "- **A**키나 **B**키를 이용해서 현재 cell의 위 혹은 아래에 새로운 cell을 추가할 수 있습니다.\n",
    "- 이 노트북에서 직접 documentation을 확인할 수 있으며, 그 단축키는 **shift + tab**입니다.\n",
    "\n",
    "#### * 기타 단축키들:\n",
    "- **A** or **B** : 현재 셀 위 혹은 아래에 새로운 셀을 추가합니다.\n",
    "- **DD** : 현재 셀을 삭제합니다.\n",
    "- **Z** : 삭제한 셀을 다시 생성합니다.\n",
    "- **Y** : 현재 셀을 코드를 실행시킬 수 있는 셀로 변환합니다.\n",
    "- **M** : 현재 셀을 Markdown 셀로 변환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 순서\n",
    "---\n",
    "이 튜토리얼에서 **CNN**을 이용해 *MNIST* dataset을 분류하는 작업을 하게 됩니다.\n",
    "\n",
    "이 작업은 간단하게 분류하면 다음과 같은 순서로 진행됩니다.\n",
    "\n",
    "- MNIST 데이터베이스 다운로드 및 읽기\n",
    "- CNN 모델 제작\n",
    "- 모델 학습\n",
    "- 학습 결과 확인 및 출력\n",
    "\n",
    "기타 필요한 설명들은 코드 작성과 함께 진행하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset 받기\n",
    "---\n",
    "Tensorflow는 MNIST를 인터넷에서 받아올 수 있는 간단한 코드를 제공합니다.\n",
    "\n",
    "이를 이용해서 dataset을 원하는 디렉토리에 다운로드 받아 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST dataset이란?\n",
    "---\n",
    "[Yann LeCun 개인 홈페이지](http://yann.lecun.com/exdb/mnist/)에서 더 많은 자료를 볼 수 있습니다.\n",
    "\n",
    "MNIST dataset은 필기체 숫자를 모아놓은 이미지 데이터셋으로 여러 튜토리얼에서 딥러닝을 시작할 때 소개하는 필기체 숫자 분류를 위한 데이터셋입니다.\n",
    "6만 개의 training 데이터와 1만 개의 test 데이터로 구분되어 있으며, 다음과 같습니다.\n",
    "\n",
    "* train-images-idx3-ubyte.gz : training용 이미지 데이터\n",
    "* train-labels-idx1-ubyte.gz : training용 라벨 데이터\n",
    "* t10k-images-idx3-ubyte.gz  : test용 이미지 데이터\n",
    "* t10k-labels-idx1-ubyte.gz  : test용 라벨 데이터\n",
    "\n",
    "training용 데이터와 test용 데이터 사이에 구조적인 차이점은 없으며, 이미지 데이터는 *784(=28X28)*픽셀의 그레이 스케일 데이터이고, 라벨 데이터는 0부터 9까지의 숫자로 되어있습니다. 자세한 포맷은 위 링크 하단에 설명되어 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 모델 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow import 및 세션 열기\n",
    "---\n",
    "Tensorflow를 사용하기 위해서는 우선 패키지를 *import*해야 합니다.\n",
    "\n",
    "기본적으로 tensorflow는 모델을 먼저 구성한 이후에 실질적인 연산 과정을 시작합니다.\n",
    "\n",
    "모델을 구성한 이후에 Tensorflow에서 제공하는 연산을 위해서는 *Session*이라고 하는 클래스 변수가 필요합니다.([tf.Session](https://www.tensorflow.org/api_docs/python/tf/Session))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input과 Target data를 위한 placeholder\n",
    "---\n",
    "모델을 구성할 때, 입력과 타겟에 쓸 데이터를 위한 일종의 변수를 지정해 두어야 하는데, 이를 *placeholder*라 합니다.\n",
    "\n",
    "Output 데이터는 입력과 모델을 통해 계산할 값이므로 필요하지 않습니다.\n",
    "\n",
    "이 때, 입력은 앞서 말한대로 28&#42;28&#42;1 = 784의 차원을 가지며, 한 번에 여러 이미지를 동시에 처리할 예정이기 때문에 **(None, 784)**차원의 *placeholder*를 생성합니다.\n",
    "\n",
    "마찬가지로 출력은 0부터 9까지의 값만을 갖고, [one-hot vector](https://en.wikipedia.org/wiki/One-hot)의 형태를 가지기 때문에 **(None, 10)**차원의 *placeholder*를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "    # float32는 타입, shape은 차원\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input data reshape하기\n",
    "입력 데이터가 1차원으로 쭉 늘어져 있는 형태이기 때문에 *(높이)&#42;(너비)&#42;(색 차원)*의 형태로 reshape 해줍니다.\n",
    "\n",
    "이 때, 한 번에 여러 데이터를 처리할 것이므로 맨 앞에 데이터 수에 대한 정보를 입력해주면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -1은 자동으로 shape 모양을 정해주는 것\n",
    "X_image = tf.reshape(X, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kernel과 bias 변수 생성하기\n",
    "---\n",
    "CNN에서는 kernel이 weight의 역할을 합니다.\n",
    "\n",
    "kernel의 shape을 변수로 받아 kernel와 bias를 동시에 반환하는 함수를 작성해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initial_value(shape) :\n",
    "    \n",
    "    '''\n",
    "    shape을 받아서 차원에 맞는 Kernel 변수와 Bias 변수를 반환하는 함수\n",
    "    \n",
    "    1. Shape을 리스트로 받아서 shape_kernel에 그대로 할당\n",
    "    2. Bias의 차원과 shape의 마지막 값이 같음 (constant는 리스트를 받아서 리스트로 감쌌다)\n",
    "    3. Truncated_normal (양쪽이 잘린 정규분포)로 initialize\n",
    "    \n",
    "    '''\n",
    "    shape_kernel = shape\n",
    "    shape_bias = [shape[-1]]\n",
    "    \n",
    "    initial_kernel = tf.truncated_normal(shape = shape_kernel, stddev = 0.1)\n",
    "    initial_bias = tf.constant(0.1, shape = shape_bias)\n",
    "    \n",
    "    return tf.Variable(initial_kernel), tf.Variable(initial_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제, 만들어진 kernel과 bias를 이용해 convolution, activation function(ReLU), pooling을 수행하는 함수를 작성해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_layer(x, kernel, bias) :\n",
    "    \n",
    "    '''\n",
    "    다음 layer를 찾는 함수\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 1. Convolution\n",
    "    conv = tf.nn.conv2d(x, kernel, strides=[1, 1, 1, 1], padding= 'SAME')\n",
    "        # x와 kernel을 convolution. stride는 step을 의미. padding은 주변을 0으로 채워서 사이즈 유지하는 것.\n",
    "    \n",
    "    \n",
    "    # 2. ReLu\n",
    "    relu = tf.nn.relu(conv + bias)\n",
    "    \n",
    "    \n",
    "    # 3. Max Pooling\n",
    "    pool = tf.nn.max_pool(relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding= 'SAME')\n",
    "        # 2x2에서 가장 큰 값을 Pool, ksize에서 마지막 1은 색 차원을 의미함\n",
    "        # ksize를 맞지 않을 경우, strides와 padding을 통해 해결함\n",
    "        \n",
    "    return pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델에 대한 이해\n",
    "---\n",
    "전체적인 모습은 convolution layer 2개, fully-connected layer 2개를 통과시키는 모델입니다.\n",
    "\n",
    "그 중 첫번째 convolution layer를 먼저 설명드리겠습니다.\n",
    "\n",
    "---\n",
    "#### convolution layer\n",
    "\n",
    "우선 입력되는 데이터는 앞서 말한 바와 같이, (*28&#42;28&#42;1*)의 형태입니다. \n",
    "\n",
    "여기에 (*5&#42;5&#42;**1**&#42;32*)의 kernel과 **zero-padding**을 이용해 **convolution**을 수행하고, 여기에 bias를 더한 뒤, activation function(**ReLU**)을 통과시킵니다. \n",
    "\n",
    "그 후, (*2&#42;2*) **max-pooling**을 수행하면 결과적으로 (*14&#42;14&#42;32*) 차원의 tensor가 생성됩니다.\n",
    "\n",
    "그림으로 표현하면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![First_layer](./IMG_0169.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번째 convolutional layer를 통과한 이후, 같은 작업을 (***5&#42;5&#42;32&#42;64***) 의 차원을 갖는 kernel을 이용해 수행하게 되면 (*7&#42;7&#42;64*) 차원의 tensor가 만들어지게 됩니다.\n",
    "\n",
    "이제 그 연산을 위한 변수들 먼저 설정해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "depth = [1, 32, 64]\n",
    "k_conv, b_conv = [], []\n",
    "h_conv = [X_image]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 변수들과 앞서 작성한 함수들을 활용해 convolution layer 두 개를 작성해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 첫번째 1, 32의 depth\n",
    "# 두번째 32, 64의 depth\n",
    "\n",
    "for i in range(2) :\n",
    "    tmp_v, tmp_b = initial_value([5, 5, depth[i], depth[i+1]])\n",
    "    k_conv.append(tmp_v)\n",
    "    b_conv.append(tmp_b)\n",
    "    \n",
    "    h_conv.append(get_next_layer(h_conv[i], k_conv[i], b_conv[i]))\n",
    "    \n",
    "    \n",
    "# 결과는 7 x 7 x 64 의 텐서가 만들어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fully connected layer\n",
    "---\n",
    "이제 fully connected layer를 작성할 차례입니다.\n",
    "\n",
    "이 작업을 위해서 (*7&#42;7&#42;64*) 차원의 tensor를 길게 펼친 뒤, fully connected layer를 이용해 1024개짜리 vector로 만들어줍니다.\n",
    "\n",
    "그 후, 두 번째 layer를 이용해 10-vector를 만들어 타겟과 비교할 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 convolution layer의 마지막 층을 vector로 변환하고, 작업들을 위한 변수를 설정해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_fc = [tf.reshape(h_conv[-1], [-1, 7*7*64])]\n",
    "\n",
    "dim_fc = [7*7*64, 1024, 10]\n",
    "weights, biases = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 변수들을 이용해서 fully connected layer를 계산해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(2) :\n",
    "    tmp_v, tmp_b = initial_value([dim_fc[i], dim_fc[i+1]])\n",
    "    weights.append(tmp_v)\n",
    "    biases.append(tmp_b)\n",
    "\n",
    "h_fc.append(tf.nn.relu(tf.matmul(h_fc[-1], weights[0]) + biases[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1024라는 숫자는 아무래도 큰 것 같으니 dropout을 이용해서 overfitting 문제를 예방해봅시다.\n",
    "\n",
    "dropout 확률은 학습시와 정확도 계산시 변경할 수 있도록 placeholder를 이용해 지정합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1024에서 10으로 가면 그 변화가 너무 크다\n",
    "# tf에서 제공하는 dropout function을 사용\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "    # keep 할 확률을 정함\n",
    "h_fc.append(tf.nn.dropout(h_fc[-1], keep_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 softmax함수를 이용해서 타겟과 비교할 y를 만들어봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_conv = tf.nn.softmax(tf.matmul(h_fc[-1], weights[1]) +biases[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loss function 및 정확도 계산하기\n",
    "---\n",
    "이제 학습을 위해 cross entropy를 구하고, optimizer를 만들어봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entrophy = tf.reduce_mean(-tf.reduce_sum(y * tf.log(y_conv), reduction_indices=[1]))\n",
    "    #reduction_indices는 더할 축을 결정함\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entrophy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 그 결과를 출력하기 위해 정확도를 계산하는 코드를 작성해봅시다.\n",
    "\n",
    "우선 타겟과 출력 data에서 가장 큰 값이 어디있는지 *argmax*함수를 통해 찾은 뒤, 그 두 값이 같은지 다른지 boolean값으로 판별합니다.\n",
    "\n",
    "그 후, 그 값들을 1과 0으로 type casting하여 평균을 구하면, 우리가 원하는 정확도 값을 구할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y, 1))\n",
    "    # T/F 반환\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "    # float으로 casting함 (True -> 1, False -> 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 진행하기\n",
    "---\n",
    "이제 모델은 완성되었습니다!\n",
    "\n",
    "이제 남은 일은 변수를 초기화하고 학습을 진행시키는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 변수 초기화하기\n",
    "---\n",
    "변수를 초기화하는 것은 세션을 이용해 간단히 끝낼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "    # 모든 변수 초기화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습 진행하기\n",
    "---\n",
    "반복문을 이용해 학습을 진행해봅시다.\n",
    "\n",
    "mini batch의 크기는 50이고, 따라서 1200번마다 모든 데이터를 학습에 이용하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.06\n",
      "step 120, training accuracy 0.84\n",
      "step 240, training accuracy 0.92\n",
      "step 360, training accuracy 0.94\n",
      "step 480, training accuracy 0.94\n",
      "step 600, training accuracy 0.94\n"
     ]
    }
   ],
   "source": [
    "for i in range(601) :\n",
    "    batch = mnist.train.next_batch(50)   #50개씩 받아온다. 메모리에 따라 키워도 된다.\n",
    "    \n",
    "    if i != 0 :\n",
    "        train_step.run(feed_dict={X: batch[0], y : batch[1], keep_prob:0.5})\n",
    "        \n",
    "    if i%120 == 0 :\n",
    "        train_accuracy = accuracy.eval(feed_dict={ X: batch[0], y : batch[1], keep_prob : 1.0} )\n",
    "        print(\"step %d, training accuracy %g\" % (i, train_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 확인하기\n",
    "---\n",
    "이제 학습이 모두 끝났고, 남은 것은 test dataset을 이용하여 얼마나 좋은 정확도를 확인하는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.9469\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy %g\" % (accuracy.eval(feed_dict={X:mnist.test.images, y : mnist.test.labels, keep_prob : 1.0})))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
