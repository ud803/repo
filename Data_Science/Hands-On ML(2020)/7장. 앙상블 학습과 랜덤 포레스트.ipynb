{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7장. 앙상블 학습과 랜덤 포레스트\n",
    "\n",
    "무작위로 선정된 수천 명의 사람에게 복잡한 질문을 하고 대답을 모은다고 가정해보자. 많은 경우 이렇게 모은 답이 전문가의 답보다 낫다.\n",
    "\n",
    "이를 대중의 지혜라고 한다. 이와 비슷하게 일련의 예측기로부터 예측을 수집하면 가장 좋은 모델 하나보다 더 좋은 예측을 얻을 수 있을 것이다.\n",
    "\n",
    "이런 일련의 예측기를 **앙상블 Ensemble**이라고 부르고, 이를 **앙상블 학습 Ensemble Learning**이라고 하며, 앙상블 학습 알고리즘을 **앙상블 방법 Ensemble Method**라고 한다.\n",
    "\n",
    "앞에서 본 결정 트리의 경우, 훈련 세트로부터 무작위로 각기 다른 서브셋을 만들어 일련의 결정 트리 분류기를 훈련시킬 수 있고, 모든 개별 트리의 예측을 모아 가장 많은 선택을 받은 클래스를 예측으로 삼을 수 있다.\n",
    "\n",
    "결정 트리의 앙상블을 **랜덤 포레스트 Random Forest**라고 하며, 가장 간단한 방법임에도 오늘날 가장 강력한 머신러닝 알고리즘 중 하나이다.\n",
    "\n",
    "게다가 프로젝트의 마지막에 다다르면 흔히 앙상블 방법을 사용하여 이미 만든 여러 괜찮은 예측기를 연결하여 더 좋은 예측기를 만들곤 한다. 실제로 많은 머신러닝 경연 대회에서 우승하는 솔루션은 여러 앙상블 방법인 경우가 많고, 특히 넷플릭스 대회에서 그러한 경향을 띤다.\n",
    "\n",
    "이 장에서는 랜덤 포레스트를 비롯한 **배깅, 부스팅, 스태킹** 등 가장 인기 있는 앙상블 방법을 설명한다.\n",
    "\n",
    "\n",
    "# 1. 투표 기반 분류기\n",
    "\n",
    "정확도가 80%인 분류기 여러 개를 훈련시켰다고 가정하자. 더 좋은 분류기를 만드는 매우 간단한 방법은 각 분류기의 예측을 모아서 가장 많이 선택된 클래스를 예측하는 것이다.\n",
    "\n",
    "이렇게 다수결 투표로 정해지는 분류기를 **직접 투표 Hard Voting** 분류기라고 한다. 대부분의 경우, 이 다수결 투표 분류기가 앙상블에 포함된 개별 분류기 중 가장 뛰어난 것보다도 정확도가 높은 경우가 많다.\n",
    "\n",
    "사실 각 분류기가 **약한 학습기 Weak Learner** (즉, 랜덤 추측보다 조금 더 높은 성능을 내는 분류기) 일지라고 충분하게 많고 다양하다면 앙상블은 **강한 학습기 Strong Learner**가 될 수 있다.\n",
    "\n",
    "이게 어떻게 가능할까? 이는 **큰 수의 법칙 Law of Large Number** 때문이다. 51% 정확도를 가진 1,000개의 분류기로 앙상블 모델을 구축한다고 가정할 경우, 75%의 정확도를 기대할 수 있다.\n",
    "\n",
    "하지만 이런 가정은 모든 분류기가 완벽하게 독립적이고 오차에 상관관계가 없어야 가능하다.\n",
    "\n",
    "사이킷런의 투표 기반 분류기를 만들고 훈련시켜보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_moons(n_samples = 500, noise=0.3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='auto',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='liblinear', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     ccp_alpha=0.0,\n",
       "                                                     class_weight=Non...\n",
       "                                                     oob_score=False,\n",
       "                                                     random_state=None,\n",
       "                                                     verbose=0,\n",
       "                                                     warm_start=False)),\n",
       "                             ('svc',\n",
       "                              SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                                  class_weight=None, coef0=0.0,\n",
       "                                  decision_function_shape='ovr', degree=3,\n",
       "                                  gamma='auto', kernel='rbf', max_iter=-1,\n",
       "                                  probability=False, random_state=None,\n",
       "                                  shrinking=True, tol=0.001, verbose=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression(solver='liblinear')\n",
    "rnd_clf = RandomForestClassifier(n_estimators=10)\n",
    "svm_clf = SVC(gamma='auto')\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='hard'\n",
    ")\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.792\n",
      "RandomForestClassifier 0.856\n",
      "SVC 0.896\n",
      "VotingClassifier 0.896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예상대로 투표 기반 분류기가 다른 개별 분류기보다 성능이 조금 더 높다.\n",
    "\n",
    "모든 분류기가 클래스의 확률을 예측할 수 있으면, (즉, `predict_proba()` 함수가 있으면) 개별 분류기의 예측을 평균 내어 확률이 가장 높은 클래스를 예측할 수 있다.\n",
    "\n",
    "이를 **간접 투표 Soft Voting** 방식이라고 한다. 이 방식은 확률이 높은 투표에 비중을 더 두기 때문에 직접 투표 방식보다 성능이 높다.\n",
    "\n",
    "이 방식을 사용하려면 `voting=\"soft\"`로 바꾸고, 모든 분류기가 클래스의 확률을 추정할 수 있으면 된다.\n",
    "\n",
    "`SVC`는 기본값에서 확률을 제공하지 않으므로 `probability` 매개변수를 `True`로 지정해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='auto',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='liblinear', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     ccp_alpha=0.0,\n",
       "                                                     class_weight=Non...\n",
       "                                                     oob_score=False,\n",
       "                                                     random_state=None,\n",
       "                                                     verbose=0,\n",
       "                                                     warm_start=False)),\n",
       "                             ('svc',\n",
       "                              SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                                  class_weight=None, coef0=0.0,\n",
       "                                  decision_function_shape='ovr', degree=3,\n",
       "                                  gamma='auto', kernel='rbf', max_iter=-1,\n",
       "                                  probability=True, random_state=None,\n",
       "                                  shrinking=True, tol=0.001, verbose=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression(solver='liblinear')\n",
    "rnd_clf = RandomForestClassifier(n_estimators=10)\n",
    "svm_clf = SVC(gamma='auto', probability=True)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='soft'\n",
    ")\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.792\n",
      "RandomForestClassifier 0.88\n",
      "SVC 0.896\n",
      "VotingClassifier 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "간접 투표 방식을 사용하면 일반적으로 정확도가 더 높다. (내 경우는 더 낮게 나왔다.)\n",
    "\n",
    "# 2. 배깅과 페이스팅\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
