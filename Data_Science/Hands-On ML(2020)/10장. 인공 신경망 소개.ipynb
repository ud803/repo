{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10장. 인공 신경망 소개\n",
    "\n",
    "많은 인간의 발명품은 자연으로부터 영감을 얻었다. 그렇다면 지능적인 기계에 대해 영감을 얻기 위해서는 뇌의 구조를 살펴보는 것이 합리적일 것이다.\n",
    "\n",
    "이것이 **인공 신경망 Artificial Neural Networks, ANN**의 핵심 아이디어이다. 그러나 새를 보고 비행기에 대한 영감을 얻었다고 하더라도 비행기의 날개를 펄럭거릴 필요는 없다.\n",
    "\n",
    "비슷한 원리로 인공 신경망도 생물학적 뉴런에서부터 점점 멀어지고 있으며, 어떤 연구자들은 생물학적으로 국한되지 않도록 생물학적 비교를 모두 버려야 한다고 주장하기도 한다.\n",
    "\n",
    "(예를 들면, '뉴런' 대신 '유닛'이라고 부른다.)\n",
    "\n",
    "인공 신경망은 딥러닝의 핵심이다. 수백만 개의 이미지를 분류하거나, 음성 인식 서비스의 성능을 높이거나, 수억 명의 사용자에게 가장 좋은 비디오를 추천해주거나, 바둑 세계챔피언을 이기기 위해 기보를 익히는 등 아주 복잡한 대규모 머신러닝 문제를 다루는 데 적합하다.\n",
    "\n",
    "이 장에서는 인공 신경망의 초창기 구조를 간단히 소개하는 것으로 시작한다. 그런 다음 **다층 퍼셉트론 Multi-Layer Perceptron, MLP**을 설명하고 MNIST 숫자 분류 문제를 텐서플로를 사용해 구현해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 생물학적 뉴런에서 인공 뉴런까지\n",
    "\n",
    "## 1.1 생물학적 뉴런\n",
    "## 1.2 뉴런을 사용한 논리연산\n",
    "\n",
    "**인공 뉴런 Artificial Neuron**은 하나 이상의 이진 입력과 하나의 이진 출력을 가진다. 맥컬록과 피츠는 이런 간단한 모델을 가지고 인공 뉴런의 네트워크를 만들어 어떤 논리 명제도 계산할 수 있다는 것을 보였다.\n",
    "\n",
    "## 1.3 퍼셉트론\n",
    "\n",
    "**퍼셉트론 Perceptron**은 가장 간단한 인공 신경망 구조 중 하나로 **TLU, Threshold Logic Unit**라는 조금 다른 형태의 인공 뉴런을 기반으로 한다.\n",
    "\n",
    "입력과 출력이 이진값이 아닌 어떤 숫자고 각각의 입력 연결은 가중치와 연결되어 있다.\n",
    "\n",
    "TLU는 입력의 가중치 합을 계산하고 ( $ z = w_1x_1 + w_2x_2 + ... + w_nx_n = w^T\\times x $), 그런 다음 계산된 합에 **계단 함수 Step Function**를 적용하여 그 결과를 출력한다.\n",
    "\n",
    "즉, $h_w(x) = step(z) = step(w^T\\times x) $ 이다.\n",
    "\n",
    "퍼셉트론에서 가장 널리 사용되는 계단 함수는 **헤비사이드 계단 함수 Heaviside Step Function**이다. 이따금 부호 함수 Sign Function을 대신 사용하기도 한다.\n",
    "\n",
    "하나의 TLU는 간단한 선형 이진 분류 문제에 사용할 수 있다. 입력의 선형 조합을 계산해서 그 결과가 임곗값을 넘어서면 양성 클래스를 출력하고 그렇지 않으면 음성 클래스를 출력한다.\n",
    "\n",
    "예를 들어 하나의 TLU를 이용해 꽃잎의 길이와 너비를 기반으로 붓꽃의 품종을 분류할 수 있다. TLU를 훈련시킨다는 것은 최적의 $w_0, w_1, w_2$를 찾는다는 뜻이다.\n",
    "\n",
    "퍼셉트론은 층이 하나뿐인 TLU로 구성된다. 각 뉴런은 모든 입력에 연결되어 있으며, 이 연결은 **입력 뉴런 Input Neuron**이라 부르는 특별한 통과 뉴런을 사용해 표현되곤 한다.\n",
    "\n",
    "이 뉴런은 무엇이 주입되는 입력을 그냥 출력으로 통과시킨다. 보통 거기에 편향 특성이 더해지며 ($x_0 = 1$), 이 편향 특성은 항상 1을 출력하는 특별한 종류의 뉴런인 **편향 뉴런 Bias Neuron**으로 표현된다.\n",
    "\n",
    "그렇다면 퍼셉트론은 어떻게 훈련될까? 프랑크 로젠블라트가 제안한 퍼셉트론의 훈련 알고리즘은 **헤브의 규칙, Hebb's Rule**으로부터 영감을 많이 받았다. 서로 활성화되는 세포가 서로 연결된다는 규칙으로써, 이는 후에 헤브의 규칙 또는 헤브 학습으로 알려지게 되었다.\n",
    "\n",
    "즉, 두 뉴런이 동일한 출력을 낼 때마다 그들 사이의 연결 가중치가 증가한다. 퍼셉트론은 네트워크가 만드는 에러를 반영하도록 조금 변형된 규칙을 사용하여 훈련된다.\n",
    "\n",
    "잘못된 출력을 만드는 연결은 강화시키지 않는데, 조금 더 구체적으로 말하면 퍼셉트론에 한 번에 한 개의 샘플이 주입되면 각 샘플에 대해 예측이 만들어진다.\n",
    "\n",
    "잘못된 예측을 하는 모든 출력 뉴런에 대해 올바른 예측을 만들 수 있도록 입력에 연결된 가중치를 강화시킨다. 규칙은 아래와 같다.\n",
    "\n",
    "$$ {w_{i,j}}^{(next step)} = w_{i,j} + \\eta(y_j - \\hat{y_j})x_i $$\n",
    "\n",
    "각 출력 뉴런의 결정 경계는 선형이므로 퍼셉트론도 복잡한 패턴을 학습하지 못한다. 하지만 로젠블랴트는 훈련 샘플이 선형적으로 구분될 수 있다면 이 알고리즘이 정답에 수렴한다는 것을 보였다.\n",
    "\n",
    "이를 **퍼셉트론 수렴 이론 Perceptron Convergence Theorem**이라고 한다.\n",
    "\n",
    "사이킷런은 하나의 TLU 네트워크를 구현한 Perceptron 클래스를 제공한다. 이 파이썬 클래스도 동일한 방식으로 사용할 수 있는데, 예를 들어 붓꽃 데이터셋에 아래와 같이 적용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ud803\\Anaconda3\\envs\\hands_on_ml\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2,3)]\n",
    "y = (iris.target == 0).astype(np.int)\n",
    "\n",
    "per_clf = Perceptron(random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아마 퍼셉트론 학습 알고리즘이 확률적 경사 하강법과 매우 닮았다고 느꼈을 것이다. 사이킷런의 Perceptron 클래스는 매개변수가 `loss=\"perceptron\"`, `learning_rate=\"constant\"`, `eta0=1`, `penalty=None`인 `SGDClassifier`와 같다.\n",
    "\n",
    "로지스틱 회귀 분류기와 달리 퍼셉트론은 클래스 확률을 제공하지 않으며 고정된 임곗값을 기준으로 예측을 만든다. 이런 이유로 퍼셉트론보다 로지스틱 회귀가 선호된다.\n",
    "\n",
    "1969년 퍼셉트론의 여러 약점이 언급되었는데, 실제로 일부 간단한 문제를 풀 수 없다는 것이 입증되었다. (예를 들면 **배타적 논리합 XOR** 분류 문제). 물론 이는 다른 선형분류기도 마찬가지이다. \n",
    "\n",
    "하지만 연구자들은 퍼셉트론에 많은 기대를 했었기 때문에 실망도 컸고, 신경망 연구가 쇠약해지는 길이 되었다.\n",
    "\n",
    "그러나 여러 퍼셉트론을 쌓아올려 일부 제약을 줄일 수 있다는 사실이 밝혀졌다. 이런 인공 신경망을 **다층 퍼셉트론, Multi-Layer Perceptron, MLP**이라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1.4 다층 퍼셉트론과 역전파\n",
    "\n",
    "다층 퍼셉트론은 (통과) 입력층 하나와 **은닉층 Hidden Layer**이라 불리는 하나 이상의 TLU 층과 마지막 층인 **출력층 Output Layer**으로 구성된다.\n",
    "\n",
    "출력층을 제외하고 모든 층은 편향 뉴런을 포함하여 다음 층과 완전히 연결되어 있다.인공 신경망의 은닉층이 2개 이상일 때 이를 **심층 신경망, Deep Neural Network, DNN**이라고 한다.\n",
    "\n",
    "연구자들은 다층 퍼셉트론을 훈련시킬 방법을 찾기 위해 고군분투하다가, 1986년 **역전파 훈련 알고리즘, Backpropagation**을 소개하는 획기적인 논문이 공개되었다.\n",
    "\n",
    "요즘에는 이를 후진 모드 자동 미분을 사용하는 경사 하강법으로 기술한다.\n",
    "\n",
    "- 알고리즘은 각 훈련 샘플을 네트워크에 주입하고 연속되는 각 층의 뉴런마다 출력을 계산한다.\n",
    "- 그런 다음 네트워크의 출력 오차를 계산한다. (기댓값과 네트워크 실제 출력과의 차이)\n",
    "- 그리고 각 출력 뉴런의 오차에 마지막 은닉층의 뉴런이 얼마나 기여했는지 측정한다.\n",
    "- 그런 다음 이전 은닉층의 뉴런이 여기에 또 얼마나 기여했는지 측정한다. 이런 식으로 입력층에 도달할 때까지 반복한다.\n",
    "- 이 역방향 과정은 오차 그래디언트를 후방으로 전파함으로써 네트워크의 모든 연결 가중치에 대한 오차 그래디언트를 효율적으로 계산한다.\n",
    "- 마지막으로 오차 그래디언트를 네트워크의 모든 연결 가중치에 반영하는 경사 하강법을 적용한다.\n",
    "\n",
    "즉, 요약하자면\n",
    "- 각 훈련 샘플에 대한 역전파 알고리즘이 먼저 예측을 만들고 (**정방향 계산**)\n",
    "- 오차를 측정하고\n",
    "- 그 다음 역방향으로 각 연결이 오차에 기여한 정도를 측정한다. (**역방향 계산**)\n",
    "- 마지막으로 이 오차가 감소하도록 가중치를 조금씩 조정한다. (**경사 하강법 스텝**)\n",
    "\n",
    "이 알고리즘을 잘 작동시키기 위해 저자들은 다중 퍼셉트론 구조에 중요한 변화를 주었는데, 계단 함수를 로지스틱 함수 $\\sigma(z) = \\frac{1}{1+exp(-z)}$로 바꾼 것이다.\n",
    "\n",
    "계단 함수에는 수평선밖에 없으니 계산할 그래디언트가 없다. (경사 하강법은 평편한 곳을 이동할 수 없다.)\n",
    "\n",
    "반면 로지스틱 함수는 어디서든지 0이 아닌 그래디언트가 잘 정의되어 있다. 역전파 알고리즘은 로지스틱 함수 대신 다른 **활성화 함수 Activation Function**와도 사용될 수 있다.\n",
    "\n",
    "널리 쓰이는 두 개의 다른 활성화 함수는 아래와 같다.\n",
    "\n",
    "---\n",
    "\n",
    "- **하이퍼볼릭 탄젠트 함수** (쌍곡 탄젠트 함수)\n",
    "\n",
    "$tanh(z) = 2\\sigma(2z)-1$ 로지스틱 함수처럼 S자 모양이며, 연속이고 미분 가능하다. 하지만 출력 범위가 -1에서 1 사이이다. (로지스틱은 0과 1 사이)\n",
    "\n",
    "그래서 훈련 초기에 각 층의 출력이 다소 정규화되는 경향이 있다. (즉, 원점 주위로 몰리게 된다.) 이는 종종 빠른 수렴을 도와준다.\n",
    "\n",
    "- **ReLU 함수**\n",
    "\n",
    "$ReLU(z) = max(0, z)$ 연속적이지만 z = 0에서 미분 가능하지 않다. (기울기가 갑자기 변해서 경사 하강법이 엉뚱한 곳으로 튈 수 있다.)\n",
    "\n",
    "그러나 실제로는 잘 작동하고 계산 속도가 빠르다는 장점이 있다. 무엇보다 중요한 점은 출력에 최댓값이 없다는 점이 경사 하강법에 있는 일부 문제를 완화해준다.\n",
    "\n",
    "---\n",
    "\n",
    "다층 퍼셉트론은 각 출력이 서로 다른 이진 클래스에 대응되는 분류 문제에 자주 사용된다. 클래스가 배타적일 때 (예를 들면 숫자 이미지 분류의 0에서 9까지 클래스일 때)는 전형적으로 출력층의 활성화 함수를 **소프트맥스 Softmax** 함수로 바꿔준다.\n",
    "\n",
    "각 뉴런의 출력은 이에 상응하는 클래스의 추정 확률이 된다. 신호가 입력에서 출력으로 한 방향으로만 흐르기 때문에 이런 구조를 **피드포워드 신경망, Feedforward Neural Network, FNN**이라고 한다.\n",
    "\n",
    "---\n",
    "\n",
    "**Note.** 생물학적 뉴런이 S자 모양의 시그모이드 활성화 함수를 구현한 것처럼 보여 오랫동안 연구자들은 시그모이드 함수에만 집중하고 있었다. 하지만 일반적으로 ReLU 함수가 인공 신경망에서 더 잘 작동한다는 것이 밝혀졌다. 이것이 생물학적 비유가 오해를 일으킨 사례 중 하나이다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 텐서플로의 고수준 API로 다층 퍼셉트론 훈련하기\n",
    "\n",
    "텐서플로로 다층 퍼셉트론(MLP)을 훈련시키는 가장 간단한 방법은 사이킷런과 호환되는 고수준 API인 TF.Learn을 사용하는 것이다. \n",
    "\n",
    "`DNNClassifier` 파이썬 클래스는 여러 개의 은닉층과 클래스의 확률 추정을 위한 소프트맥스 출력층으로 구성된 심층 신경망을 매우 쉽게 훈련시켜준다.\n",
    "\n",
    "예를 들어 다음 코드는 은닉층 2개(각각의 뉴런 수는 300개, 100개)와 10개의 뉴런을 가진 소프트맥스 출력층 하나로 구성된 분류 문제용 심층 신경망을 훈련시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ud803\\AppData\\Local\\Temp\\tmp6h5elv9b\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ud803\\\\AppData\\\\Local\\\\Temp\\\\tmp6h5elv9b', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000023F3E33E908>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\ud803\\AppData\\Local\\Temp\\tmp6h5elv9b\\model.ckpt.\n",
      "INFO:tensorflow:loss = 117.19475, step = 1\n",
      "INFO:tensorflow:global_step/sec: 657.751\n",
      "INFO:tensorflow:loss = 7.757429, step = 101 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.488\n",
      "INFO:tensorflow:loss = 16.058535, step = 201 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.259\n",
      "INFO:tensorflow:loss = 18.19836, step = 301 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 793.726\n",
      "INFO:tensorflow:loss = 12.736313, step = 401 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 781.077\n",
      "INFO:tensorflow:loss = 20.241272, step = 501 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 799.823\n",
      "INFO:tensorflow:loss = 5.1634245, step = 601 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.144\n",
      "INFO:tensorflow:loss = 4.263631, step = 701 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 813.341\n",
      "INFO:tensorflow:loss = 7.310817, step = 801 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 769.057\n",
      "INFO:tensorflow:loss = 9.001286, step = 901 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 763.189\n",
      "INFO:tensorflow:loss = 6.010743, step = 1001 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.804\n",
      "INFO:tensorflow:loss = 3.3916397, step = 1101 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 813.804\n",
      "INFO:tensorflow:loss = 3.703188, step = 1201 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 813.04\n",
      "INFO:tensorflow:loss = 2.8484557, step = 1301 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.15\n",
      "INFO:tensorflow:loss = 2.9691222, step = 1401 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.259\n",
      "INFO:tensorflow:loss = 7.6608434, step = 1501 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.257\n",
      "INFO:tensorflow:loss = 2.006018, step = 1601 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 793.117\n",
      "INFO:tensorflow:loss = 3.5950933, step = 1701 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 769.055\n",
      "INFO:tensorflow:loss = 0.7369841, step = 1801 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.829\n",
      "INFO:tensorflow:loss = 1.1076659, step = 1901 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.142\n",
      "INFO:tensorflow:loss = 1.9267602, step = 2001 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.264\n",
      "INFO:tensorflow:loss = 3.731576, step = 2101 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.817\n",
      "INFO:tensorflow:loss = 2.6757562, step = 2201 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 757.413\n",
      "INFO:tensorflow:loss = 4.789159, step = 2301 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.824\n",
      "INFO:tensorflow:loss = 2.2362275, step = 2401 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.26\n",
      "INFO:tensorflow:loss = 8.782459, step = 2501 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.259\n",
      "INFO:tensorflow:loss = 4.1418076, step = 2601 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.26\n",
      "INFO:tensorflow:loss = 4.460539, step = 2701 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.15\n",
      "INFO:tensorflow:loss = 2.0941958, step = 2801 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.259\n",
      "INFO:tensorflow:loss = 0.54131645, step = 2901 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 815.457\n",
      "INFO:tensorflow:loss = 0.53564155, step = 3001 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.262\n",
      "INFO:tensorflow:loss = 14.5474825, step = 3101 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.488\n",
      "INFO:tensorflow:loss = 2.0418425, step = 3201 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.142\n",
      "INFO:tensorflow:loss = 1.9883553, step = 3301 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.265\n",
      "INFO:tensorflow:loss = 0.13837753, step = 3401 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.267\n",
      "INFO:tensorflow:loss = 0.2984713, step = 3501 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.15\n",
      "INFO:tensorflow:loss = 2.694781, step = 3601 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.487\n",
      "INFO:tensorflow:loss = 0.44269255, step = 3701 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.824\n",
      "INFO:tensorflow:loss = 0.79511666, step = 3801 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.49\n",
      "INFO:tensorflow:loss = 1.0533948, step = 3901 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.147\n",
      "INFO:tensorflow:loss = 3.843995, step = 4001 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.139\n",
      "INFO:tensorflow:loss = 6.1663237, step = 4101 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.493\n",
      "INFO:tensorflow:loss = 4.3594847, step = 4201 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.145\n",
      "INFO:tensorflow:loss = 4.162838, step = 4301 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.823\n",
      "INFO:tensorflow:loss = 0.10609015, step = 4401 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.491\n",
      "INFO:tensorflow:loss = 0.49727124, step = 4501 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 783.269\n",
      "INFO:tensorflow:loss = 0.5780172, step = 4601 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 793.47\n",
      "INFO:tensorflow:loss = 1.6055896, step = 4701 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.829\n",
      "INFO:tensorflow:loss = 7.6599584, step = 4801 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.145\n",
      "INFO:tensorflow:loss = 1.7151123, step = 4901 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.826\n",
      "INFO:tensorflow:loss = 0.5544401, step = 5001 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 781.074\n",
      "INFO:tensorflow:loss = 0.14094016, step = 5101 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 799.82\n",
      "INFO:tensorflow:loss = 0.40041587, step = 5201 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.49\n",
      "INFO:tensorflow:loss = 0.09455833, step = 5301 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.148\n",
      "INFO:tensorflow:loss = 1.5713903, step = 5401 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.823\n",
      "INFO:tensorflow:loss = 6.6146297, step = 5501 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 775.006\n",
      "INFO:tensorflow:loss = 1.1223091, step = 5601 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 763.204\n",
      "INFO:tensorflow:loss = 0.90795994, step = 5701 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 793.471\n",
      "INFO:tensorflow:loss = 0.2013355, step = 5801 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.488\n",
      "INFO:tensorflow:loss = 1.3208306, step = 5901 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.821\n",
      "INFO:tensorflow:loss = 0.7532777, step = 6001 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.147\n",
      "INFO:tensorflow:loss = 1.248382, step = 6101 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.276\n",
      "INFO:tensorflow:loss = 0.89581007, step = 6201 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.483\n",
      "INFO:tensorflow:loss = 0.3913197, step = 6301 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.146\n",
      "INFO:tensorflow:loss = 0.47335914, step = 6401 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 847.266\n",
      "INFO:tensorflow:loss = 0.59999466, step = 6501 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.151\n",
      "INFO:tensorflow:loss = 0.1150507, step = 6601 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.149\n",
      "INFO:tensorflow:loss = 0.36714977, step = 6701 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.267\n",
      "INFO:tensorflow:loss = 0.17826709, step = 6801 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.15\n",
      "INFO:tensorflow:loss = 0.5239805, step = 6901 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.255\n",
      "INFO:tensorflow:loss = 0.25154597, step = 7001 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.152\n",
      "INFO:tensorflow:loss = 0.61954874, step = 7101 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.824\n",
      "INFO:tensorflow:loss = 2.8086958, step = 7201 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.27\n",
      "INFO:tensorflow:loss = 0.3764766, step = 7301 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.14\n",
      "INFO:tensorflow:loss = 6.9485416, step = 7401 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.267\n",
      "INFO:tensorflow:loss = 0.48241454, step = 7501 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.145\n",
      "INFO:tensorflow:loss = 0.2685013, step = 7601 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.143\n",
      "INFO:tensorflow:loss = 0.5671433, step = 7701 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.153\n",
      "INFO:tensorflow:loss = 0.04884672, step = 7801 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.145\n",
      "INFO:tensorflow:loss = 0.108401015, step = 7901 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.142\n",
      "INFO:tensorflow:loss = 0.3261383, step = 8001 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.828\n",
      "INFO:tensorflow:loss = 0.91068345, step = 8101 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.49\n",
      "INFO:tensorflow:loss = 0.42775333, step = 8201 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.267\n",
      "INFO:tensorflow:loss = 0.44066232, step = 8301 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 799.825\n",
      "INFO:tensorflow:loss = 0.10021818, step = 8401 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.82\n",
      "INFO:tensorflow:loss = 0.7465746, step = 8501 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.149\n",
      "INFO:tensorflow:loss = 0.14682159, step = 8601 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.26\n",
      "INFO:tensorflow:loss = 0.11347248, step = 8701 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.146\n",
      "INFO:tensorflow:loss = 1.9146621, step = 8801 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.153\n",
      "INFO:tensorflow:loss = 0.47039592, step = 8901 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.145\n",
      "INFO:tensorflow:loss = 0.07003082, step = 9001 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.254\n",
      "INFO:tensorflow:loss = 0.109204754, step = 9101 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.241\n",
      "INFO:tensorflow:loss = 0.14794561, step = 9201 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.28\n",
      "INFO:tensorflow:loss = 0.08216543, step = 9301 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.495\n",
      "INFO:tensorflow:loss = 0.46681502, step = 9401 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.821\n",
      "INFO:tensorflow:loss = 0.18424445, step = 9501 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.262\n",
      "INFO:tensorflow:loss = 0.0578779, step = 9601 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.821\n",
      "INFO:tensorflow:loss = 0.32169753, step = 9701 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.279\n",
      "INFO:tensorflow:loss = 0.40879747, step = 9801 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.821\n",
      "INFO:tensorflow:loss = 0.4619033, step = 9901 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.257\n",
      "INFO:tensorflow:loss = 0.09640157, step = 10001 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.271\n",
      "INFO:tensorflow:loss = 0.4836777, step = 10101 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.488\n",
      "INFO:tensorflow:loss = 0.099620886, step = 10201 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.27\n",
      "INFO:tensorflow:loss = 3.4039829, step = 10301 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.49\n",
      "INFO:tensorflow:loss = 0.10486429, step = 10401 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.264\n",
      "INFO:tensorflow:loss = 0.5986388, step = 10501 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.259\n",
      "INFO:tensorflow:loss = 0.09880425, step = 10601 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.828\n",
      "INFO:tensorflow:loss = 0.5261555, step = 10701 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.254\n",
      "INFO:tensorflow:loss = 0.71951455, step = 10801 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.262\n",
      "INFO:tensorflow:loss = 0.34928817, step = 10901 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.145\n",
      "INFO:tensorflow:loss = 0.74395037, step = 11001 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.267\n",
      "INFO:tensorflow:loss = 0.42482808, step = 11101 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.824\n",
      "INFO:tensorflow:loss = 1.1274871, step = 11201 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.485\n",
      "INFO:tensorflow:loss = 0.2724738, step = 11301 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.488\n",
      "INFO:tensorflow:loss = 0.027517416, step = 11401 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.491\n",
      "INFO:tensorflow:loss = 0.17237303, step = 11501 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.483\n",
      "INFO:tensorflow:loss = 0.16305985, step = 11601 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.262\n",
      "INFO:tensorflow:loss = 0.026919805, step = 11701 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.488\n",
      "INFO:tensorflow:loss = 0.21060827, step = 11801 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.49\n",
      "INFO:tensorflow:loss = 0.069792286, step = 11901 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 781.075\n",
      "INFO:tensorflow:loss = 0.03976015, step = 12001 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.267\n",
      "INFO:tensorflow:loss = 0.04153573, step = 12101 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 781.072\n",
      "INFO:tensorflow:loss = 0.46074644, step = 12201 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 775.021\n",
      "INFO:tensorflow:loss = 0.47174755, step = 12301 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.49\n",
      "INFO:tensorflow:loss = 0.05090917, step = 12401 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.148\n",
      "INFO:tensorflow:loss = 0.33100578, step = 12501 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.488\n",
      "INFO:tensorflow:loss = 0.02793679, step = 12601 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.147\n",
      "INFO:tensorflow:loss = 0.18225867, step = 12701 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.144\n",
      "INFO:tensorflow:loss = 0.33387023, step = 12801 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.146\n",
      "INFO:tensorflow:loss = 0.089826874, step = 12901 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.146\n",
      "INFO:tensorflow:loss = 0.16079499, step = 13001 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.15\n",
      "INFO:tensorflow:loss = 0.044260424, step = 13101 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.148\n",
      "INFO:tensorflow:loss = 0.035309047, step = 13201 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.262\n",
      "INFO:tensorflow:loss = 0.032726508, step = 13301 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 847.267\n",
      "INFO:tensorflow:loss = 0.034812637, step = 13401 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.142\n",
      "INFO:tensorflow:loss = 0.22495554, step = 13501 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.146\n",
      "INFO:tensorflow:loss = 0.32204932, step = 13601 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.151\n",
      "INFO:tensorflow:loss = 0.0055597485, step = 13701 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.141\n",
      "INFO:tensorflow:loss = 0.010774612, step = 13801 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.152\n",
      "INFO:tensorflow:loss = 0.3539077, step = 13901 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.148\n",
      "INFO:tensorflow:loss = 0.10960872, step = 14001 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.142\n",
      "INFO:tensorflow:loss = 0.1878652, step = 14101 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.146\n",
      "INFO:tensorflow:loss = 0.1831204, step = 14201 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.151\n",
      "INFO:tensorflow:loss = 0.27826628, step = 14301 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.145\n",
      "INFO:tensorflow:loss = 0.10519686, step = 14401 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.148\n",
      "INFO:tensorflow:loss = 0.18344858, step = 14501 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.15\n",
      "INFO:tensorflow:loss = 0.027027145, step = 14601 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.142\n",
      "INFO:tensorflow:loss = 0.013492681, step = 14701 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.823\n",
      "INFO:tensorflow:loss = 0.04254289, step = 14801 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.155\n",
      "INFO:tensorflow:loss = 0.08246054, step = 14901 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.145\n",
      "INFO:tensorflow:loss = 0.07855852, step = 15001 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.145\n",
      "INFO:tensorflow:loss = 0.020149168, step = 15101 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.262\n",
      "INFO:tensorflow:loss = 0.1355259, step = 15201 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.146\n",
      "INFO:tensorflow:loss = 0.046872146, step = 15301 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.26\n",
      "INFO:tensorflow:loss = 1.4252256, step = 15401 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.26\n",
      "INFO:tensorflow:loss = 0.24278271, step = 15501 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.145\n",
      "INFO:tensorflow:loss = 0.1160372, step = 15601 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.259\n",
      "INFO:tensorflow:loss = 0.043563645, step = 15701 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.147\n",
      "INFO:tensorflow:loss = 0.17207977, step = 15801 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.149\n",
      "INFO:tensorflow:loss = 0.107376374, step = 15901 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.145\n",
      "INFO:tensorflow:loss = 0.032471254, step = 16001 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.142\n",
      "INFO:tensorflow:loss = 0.023316327, step = 16101 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.495\n",
      "INFO:tensorflow:loss = 0.06684455, step = 16201 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.26\n",
      "INFO:tensorflow:loss = 0.06464482, step = 16301 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.474\n",
      "INFO:tensorflow:loss = 0.20597583, step = 16401 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.273\n",
      "INFO:tensorflow:loss = 0.018819058, step = 16501 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.26\n",
      "INFO:tensorflow:loss = 0.21098612, step = 16601 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.821\n",
      "INFO:tensorflow:loss = 0.1574402, step = 16701 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.265\n",
      "INFO:tensorflow:loss = 0.22156528, step = 16801 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.271\n",
      "INFO:tensorflow:loss = 0.13850984, step = 16901 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.482\n",
      "INFO:tensorflow:loss = 0.055726297, step = 17001 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.495\n",
      "INFO:tensorflow:loss = 0.09281955, step = 17101 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.255\n",
      "INFO:tensorflow:loss = 0.049164277, step = 17201 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 799.818\n",
      "INFO:tensorflow:loss = 0.19346324, step = 17301 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.267\n",
      "INFO:tensorflow:loss = 0.09648602, step = 17401 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.144\n",
      "INFO:tensorflow:loss = 0.01996711, step = 17501 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.15\n",
      "INFO:tensorflow:loss = 0.02675815, step = 17601 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 787.221\n",
      "INFO:tensorflow:loss = 0.027989298, step = 17701 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.265\n",
      "INFO:tensorflow:loss = 0.03721025, step = 17801 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.483\n",
      "INFO:tensorflow:loss = 0.2985592, step = 17901 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.254\n",
      "INFO:tensorflow:loss = 0.09530389, step = 18001 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.267\n",
      "INFO:tensorflow:loss = 0.09641962, step = 18101 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.15\n",
      "INFO:tensorflow:loss = 0.015464526, step = 18201 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.488\n",
      "INFO:tensorflow:loss = 0.18128231, step = 18301 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.826\n",
      "INFO:tensorflow:loss = 0.038397733, step = 18401 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.147\n",
      "INFO:tensorflow:loss = 0.038811367, step = 18501 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.485\n",
      "INFO:tensorflow:loss = 0.022490583, step = 18601 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.823\n",
      "INFO:tensorflow:loss = 0.12901896, step = 18701 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.824\n",
      "INFO:tensorflow:loss = 0.028718261, step = 18801 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.262\n",
      "INFO:tensorflow:loss = 0.025624925, step = 18901 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.487\n",
      "INFO:tensorflow:loss = 0.033189446, step = 19001 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.829\n",
      "INFO:tensorflow:loss = 0.06897629, step = 19101 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.487\n",
      "INFO:tensorflow:loss = 0.17488456, step = 19201 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.144\n",
      "INFO:tensorflow:loss = 0.07185245, step = 19301 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.265\n",
      "INFO:tensorflow:loss = 0.04809264, step = 19401 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.483\n",
      "INFO:tensorflow:loss = 0.012327468, step = 19501 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.259\n",
      "INFO:tensorflow:loss = 0.055269085, step = 19601 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.265\n",
      "INFO:tensorflow:loss = 0.039480772, step = 19701 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.826\n",
      "INFO:tensorflow:loss = 0.058554485, step = 19801 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.147\n",
      "INFO:tensorflow:loss = 0.047948133, step = 19901 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.252\n",
      "INFO:tensorflow:loss = 0.13016897, step = 20001 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.265\n",
      "INFO:tensorflow:loss = 0.032506254, step = 20101 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.26\n",
      "INFO:tensorflow:loss = 0.0033156485, step = 20201 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.829\n",
      "INFO:tensorflow:loss = 0.07721942, step = 20301 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.257\n",
      "INFO:tensorflow:loss = 0.013428509, step = 20401 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.151\n",
      "INFO:tensorflow:loss = 0.022091215, step = 20501 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.145\n",
      "INFO:tensorflow:loss = 0.057605326, step = 20601 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.14\n",
      "INFO:tensorflow:loss = 0.017058073, step = 20701 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.264\n",
      "INFO:tensorflow:loss = 0.01040101, step = 20801 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.491\n",
      "INFO:tensorflow:loss = 0.16205853, step = 20901 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.143\n",
      "INFO:tensorflow:loss = 0.029399797, step = 21001 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.146\n",
      "INFO:tensorflow:loss = 0.044007704, step = 21101 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.264\n",
      "INFO:tensorflow:loss = 0.12237337, step = 21201 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.142\n",
      "INFO:tensorflow:loss = 0.053219315, step = 21301 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.265\n",
      "INFO:tensorflow:loss = 0.047867123, step = 21401 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.145\n",
      "INFO:tensorflow:loss = 0.042572264, step = 21501 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.823\n",
      "INFO:tensorflow:loss = 0.028455205, step = 21601 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 793.477\n",
      "INFO:tensorflow:loss = 0.0016725166, step = 21701 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.826\n",
      "INFO:tensorflow:loss = 0.011882007, step = 21801 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.145\n",
      "INFO:tensorflow:loss = 0.023451045, step = 21901 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.487\n",
      "INFO:tensorflow:loss = 0.15401027, step = 22001 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.147\n",
      "INFO:tensorflow:loss = 0.026364056, step = 22101 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.49\n",
      "INFO:tensorflow:loss = 0.06499322, step = 22201 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 799.822\n",
      "INFO:tensorflow:loss = 0.027178552, step = 22301 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.255\n",
      "INFO:tensorflow:loss = 0.0044597965, step = 22401 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 847.266\n",
      "INFO:tensorflow:loss = 0.06405644, step = 22501 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.267\n",
      "INFO:tensorflow:loss = 0.04301992, step = 22601 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.145\n",
      "INFO:tensorflow:loss = 0.021799613, step = 22701 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.487\n",
      "INFO:tensorflow:loss = 0.0066496674, step = 22801 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.264\n",
      "INFO:tensorflow:loss = 0.0088922735, step = 22901 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.146\n",
      "INFO:tensorflow:loss = 0.08417927, step = 23001 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.148\n",
      "INFO:tensorflow:loss = 0.09316226, step = 23101 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 847.264\n",
      "INFO:tensorflow:loss = 0.022009296, step = 23201 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.147\n",
      "INFO:tensorflow:loss = 0.087077305, step = 23301 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 841.204\n",
      "INFO:tensorflow:loss = 0.005576829, step = 23401 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.145\n",
      "INFO:tensorflow:loss = 0.045833103, step = 23501 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.128\n",
      "INFO:tensorflow:loss = 0.0077448506, step = 23601 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.167\n",
      "INFO:tensorflow:loss = 0.017444868, step = 23701 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.146\n",
      "INFO:tensorflow:loss = 0.010935514, step = 23801 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.151\n",
      "INFO:tensorflow:loss = 0.006834792, step = 23901 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 847.262\n",
      "INFO:tensorflow:loss = 0.05520919, step = 24001 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.151\n",
      "INFO:tensorflow:loss = 0.01894686, step = 24101 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.074\n",
      "INFO:tensorflow:loss = 0.04911243, step = 24201 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 841.959\n",
      "INFO:tensorflow:loss = 0.018462842, step = 24301 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.147\n",
      "INFO:tensorflow:loss = 0.032761127, step = 24401 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.143\n",
      "INFO:tensorflow:loss = 0.058429845, step = 24501 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.265\n",
      "INFO:tensorflow:loss = 0.043309007, step = 24601 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.149\n",
      "INFO:tensorflow:loss = 0.02294306, step = 24701 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.823\n",
      "INFO:tensorflow:loss = 0.057382315, step = 24801 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 847.264\n",
      "INFO:tensorflow:loss = 0.011007319, step = 24901 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.831\n",
      "INFO:tensorflow:loss = 0.03477526, step = 25001 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.142\n",
      "INFO:tensorflow:loss = 0.028990911, step = 25101 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.151\n",
      "INFO:tensorflow:loss = 0.025102798, step = 25201 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.148\n",
      "INFO:tensorflow:loss = 0.030939262, step = 25301 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.144\n",
      "INFO:tensorflow:loss = 0.06349337, step = 25401 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.15\n",
      "INFO:tensorflow:loss = 0.05356808, step = 25501 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.148\n",
      "INFO:tensorflow:loss = 0.02956711, step = 25601 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.146\n",
      "INFO:tensorflow:loss = 0.03775555, step = 25701 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 847.267\n",
      "INFO:tensorflow:loss = 0.011986594, step = 25801 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 847.267\n",
      "INFO:tensorflow:loss = 0.03349617, step = 25901 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.143\n",
      "INFO:tensorflow:loss = 0.033522554, step = 26001 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.146\n",
      "INFO:tensorflow:loss = 0.0259789, step = 26101 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.148\n",
      "INFO:tensorflow:loss = 0.028719995, step = 26201 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.148\n",
      "INFO:tensorflow:loss = 0.03834246, step = 26301 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.139\n",
      "INFO:tensorflow:loss = 0.05475974, step = 26401 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.155\n",
      "INFO:tensorflow:loss = 0.0052412045, step = 26501 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 847.269\n",
      "INFO:tensorflow:loss = 0.0028293252, step = 26601 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.15\n",
      "INFO:tensorflow:loss = 0.009409131, step = 26701 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.254\n",
      "INFO:tensorflow:loss = 0.009732445, step = 26801 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.26\n",
      "INFO:tensorflow:loss = 0.06453685, step = 26901 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.145\n",
      "INFO:tensorflow:loss = 0.020446349, step = 27001 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.265\n",
      "INFO:tensorflow:loss = 0.062368702, step = 27101 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.49\n",
      "INFO:tensorflow:loss = 0.0030011078, step = 27201 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.82\n",
      "INFO:tensorflow:loss = 0.049588047, step = 27301 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.824\n",
      "INFO:tensorflow:loss = 0.049627047, step = 27401 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.267\n",
      "INFO:tensorflow:loss = 0.11251529, step = 27501 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.14\n",
      "INFO:tensorflow:loss = 0.036204264, step = 27601 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.145\n",
      "INFO:tensorflow:loss = 0.033402994, step = 27701 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.265\n",
      "INFO:tensorflow:loss = 0.021027006, step = 27801 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.142\n",
      "INFO:tensorflow:loss = 0.046702363, step = 27901 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 820.211\n",
      "INFO:tensorflow:loss = 0.025916863, step = 28001 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.493\n",
      "INFO:tensorflow:loss = 0.0118510015, step = 28101 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.483\n",
      "INFO:tensorflow:loss = 0.10317975, step = 28201 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.152\n",
      "INFO:tensorflow:loss = 0.005613645, step = 28301 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.483\n",
      "INFO:tensorflow:loss = 0.09153452, step = 28401 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.264\n",
      "INFO:tensorflow:loss = 0.007154856, step = 28501 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.485\n",
      "INFO:tensorflow:loss = 0.063325435, step = 28601 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.151\n",
      "INFO:tensorflow:loss = 0.042458106, step = 28701 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.14\n",
      "INFO:tensorflow:loss = 0.0068265796, step = 28801 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.148\n",
      "INFO:tensorflow:loss = 0.059785157, step = 28901 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.371\n",
      "INFO:tensorflow:loss = 0.0019087945, step = 29001 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.142\n",
      "INFO:tensorflow:loss = 0.014523211, step = 29101 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 807.437\n",
      "INFO:tensorflow:loss = 0.030061655, step = 29201 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.254\n",
      "INFO:tensorflow:loss = 0.025655525, step = 29301 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 834.462\n",
      "INFO:tensorflow:loss = 0.058514923, step = 29401 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.56\n",
      "INFO:tensorflow:loss = 0.0056167217, step = 29501 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.262\n",
      "INFO:tensorflow:loss = 0.0106887845, step = 29601 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.273\n",
      "INFO:tensorflow:loss = 0.06286231, step = 29701 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.147\n",
      "INFO:tensorflow:loss = 0.03972615, step = 29801 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.27\n",
      "INFO:tensorflow:loss = 0.03235661, step = 29901 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.148\n",
      "INFO:tensorflow:loss = 0.0011849098, step = 30001 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.255\n",
      "INFO:tensorflow:loss = 0.025305815, step = 30101 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.207\n",
      "INFO:tensorflow:loss = 0.009902756, step = 30201 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.49\n",
      "INFO:tensorflow:loss = 0.014850439, step = 30301 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 820.598\n",
      "INFO:tensorflow:loss = 0.003150125, step = 30401 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.487\n",
      "INFO:tensorflow:loss = 0.01957139, step = 30501 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.257\n",
      "INFO:tensorflow:loss = 0.039994873, step = 30601 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.259\n",
      "INFO:tensorflow:loss = 0.04060328, step = 30701 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.262\n",
      "INFO:tensorflow:loss = 0.042853672, step = 30801 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.148\n",
      "INFO:tensorflow:loss = 0.037916914, step = 30901 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.15\n",
      "INFO:tensorflow:loss = 0.018555712, step = 31001 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.129\n",
      "INFO:tensorflow:loss = 0.019499613, step = 31101 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.424\n",
      "INFO:tensorflow:loss = 0.009204718, step = 31201 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 769.94\n",
      "INFO:tensorflow:loss = 0.010128037, step = 31301 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.262\n",
      "INFO:tensorflow:loss = 0.012850741, step = 31401 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.491\n",
      "INFO:tensorflow:loss = 0.0050338535, step = 31501 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.26\n",
      "INFO:tensorflow:loss = 0.013428506, step = 31601 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.262\n",
      "INFO:tensorflow:loss = 0.020892747, step = 31701 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.257\n",
      "INFO:tensorflow:loss = 0.039285477, step = 31801 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.262\n",
      "INFO:tensorflow:loss = 0.037694786, step = 31901 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 799.822\n",
      "INFO:tensorflow:loss = 0.019533783, step = 32001 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.483\n",
      "INFO:tensorflow:loss = 0.022246799, step = 32101 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.487\n",
      "INFO:tensorflow:loss = 0.0195778, step = 32201 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.491\n",
      "INFO:tensorflow:loss = 0.008867608, step = 32301 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 793.476\n",
      "INFO:tensorflow:loss = 0.014888094, step = 32401 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.824\n",
      "INFO:tensorflow:loss = 0.020952571, step = 32501 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.146\n",
      "INFO:tensorflow:loss = 0.013822863, step = 32601 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.488\n",
      "INFO:tensorflow:loss = 0.0046490915, step = 32701 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.186\n",
      "INFO:tensorflow:loss = 0.026066996, step = 32801 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.493\n",
      "INFO:tensorflow:loss = 0.03743177, step = 32901 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 820.426\n",
      "INFO:tensorflow:loss = 0.008947025, step = 33001 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.49\n",
      "INFO:tensorflow:loss = 0.015280383, step = 33101 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.257\n",
      "INFO:tensorflow:loss = 0.04311475, step = 33201 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 793.474\n",
      "INFO:tensorflow:loss = 0.003938311, step = 33301 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 820.761\n",
      "INFO:tensorflow:loss = 0.091218516, step = 33401 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.255\n",
      "INFO:tensorflow:loss = 0.02055335, step = 33501 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.147\n",
      "INFO:tensorflow:loss = 0.010312501, step = 33601 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.145\n",
      "INFO:tensorflow:loss = 0.0019761212, step = 33701 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.259\n",
      "INFO:tensorflow:loss = 0.0133122, step = 33801 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.262\n",
      "INFO:tensorflow:loss = 0.009555471, step = 33901 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.488\n",
      "INFO:tensorflow:loss = 0.0058886623, step = 34001 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.147\n",
      "INFO:tensorflow:loss = 0.046435654, step = 34101 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.49\n",
      "INFO:tensorflow:loss = 0.014155857, step = 34201 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.824\n",
      "INFO:tensorflow:loss = 0.0005096873, step = 34301 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 820.811\n",
      "INFO:tensorflow:loss = 0.0023195385, step = 34401 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.259\n",
      "INFO:tensorflow:loss = 0.016352378, step = 34501 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.264\n",
      "INFO:tensorflow:loss = 0.011639476, step = 34601 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.483\n",
      "INFO:tensorflow:loss = 0.038008396, step = 34701 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.148\n",
      "INFO:tensorflow:loss = 0.0077134417, step = 34801 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.828\n",
      "INFO:tensorflow:loss = 0.015779909, step = 34901 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.257\n",
      "INFO:tensorflow:loss = 0.019241363, step = 35001 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.829\n",
      "INFO:tensorflow:loss = 0.010251697, step = 35101 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.26\n",
      "INFO:tensorflow:loss = 0.04372233, step = 35201 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.485\n",
      "INFO:tensorflow:loss = 0.01917758, step = 35301 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.493\n",
      "INFO:tensorflow:loss = 0.03349161, step = 35401 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.139\n",
      "INFO:tensorflow:loss = 0.014149383, step = 35501 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.15\n",
      "INFO:tensorflow:loss = 0.006425848, step = 35601 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.149\n",
      "INFO:tensorflow:loss = 0.0070973826, step = 35701 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.142\n",
      "INFO:tensorflow:loss = 0.018915879, step = 35801 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.262\n",
      "INFO:tensorflow:loss = 0.02320066, step = 35901 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 827.219\n",
      "INFO:tensorflow:loss = 0.009496743, step = 36001 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.259\n",
      "INFO:tensorflow:loss = 0.008369456, step = 36101 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 834.241\n",
      "INFO:tensorflow:loss = 0.0055291452, step = 36201 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.15\n",
      "INFO:tensorflow:loss = 0.015300924, step = 36301 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.49\n",
      "INFO:tensorflow:loss = 0.015737962, step = 36401 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.485\n",
      "INFO:tensorflow:loss = 0.04365067, step = 36501 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.469\n",
      "INFO:tensorflow:loss = 0.010208374, step = 36601 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.823\n",
      "INFO:tensorflow:loss = 0.007878981, step = 36701 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.262\n",
      "INFO:tensorflow:loss = 0.00683936, step = 36801 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.826\n",
      "INFO:tensorflow:loss = 0.02638048, step = 36901 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.147\n",
      "INFO:tensorflow:loss = 0.028490273, step = 37001 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.259\n",
      "INFO:tensorflow:loss = 0.011394546, step = 37101 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.264\n",
      "INFO:tensorflow:loss = 0.029472755, step = 37201 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.483\n",
      "INFO:tensorflow:loss = 0.012430137, step = 37301 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 799.822\n",
      "INFO:tensorflow:loss = 0.0366207, step = 37401 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.49\n",
      "INFO:tensorflow:loss = 0.040805504, step = 37501 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.148\n",
      "INFO:tensorflow:loss = 0.010074926, step = 37601 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.144\n",
      "INFO:tensorflow:loss = 0.023521367, step = 37701 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.146\n",
      "INFO:tensorflow:loss = 0.025186988, step = 37801 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.264\n",
      "INFO:tensorflow:loss = 0.010900992, step = 37901 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.142\n",
      "INFO:tensorflow:loss = 0.0390562, step = 38001 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.15\n",
      "INFO:tensorflow:loss = 0.0062070997, step = 38101 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.828\n",
      "INFO:tensorflow:loss = 0.0012342468, step = 38201 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.482\n",
      "INFO:tensorflow:loss = 0.023647858, step = 38301 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.15\n",
      "INFO:tensorflow:loss = 0.007947704, step = 38401 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.26\n",
      "INFO:tensorflow:loss = 0.033150442, step = 38501 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.487\n",
      "INFO:tensorflow:loss = 0.027812554, step = 38601 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.487\n",
      "INFO:tensorflow:loss = 0.006433286, step = 38701 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.15\n",
      "INFO:tensorflow:loss = 0.0027476666, step = 38801 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.48\n",
      "INFO:tensorflow:loss = 0.010114381, step = 38901 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 854.516\n",
      "INFO:tensorflow:loss = 0.004920233, step = 39001 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 847.267\n",
      "INFO:tensorflow:loss = 0.008957251, step = 39101 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.124\n",
      "INFO:tensorflow:loss = 0.027682643, step = 39201 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.28\n",
      "INFO:tensorflow:loss = 0.013990726, step = 39301 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.485\n",
      "INFO:tensorflow:loss = 0.031833176, step = 39401 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.15\n",
      "INFO:tensorflow:loss = 0.0069904397, step = 39501 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.233\n",
      "INFO:tensorflow:loss = 0.02809561, step = 39601 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.512\n",
      "INFO:tensorflow:loss = 0.0034107035, step = 39701 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.15\n",
      "INFO:tensorflow:loss = 0.004096585, step = 39801 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 787.224\n",
      "INFO:tensorflow:loss = 0.0023111652, step = 39901 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.26\n",
      "INFO:tensorflow:loss = 0.004938437, step = 40001 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.228\n",
      "INFO:tensorflow:loss = 0.018590597, step = 40101 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 847.302\n",
      "INFO:tensorflow:loss = 0.00014900943, step = 40201 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 847.271\n",
      "INFO:tensorflow:loss = 0.042007346, step = 40301 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.255\n",
      "INFO:tensorflow:loss = 0.0011681602, step = 40401 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.147\n",
      "INFO:tensorflow:loss = 0.019969972, step = 40501 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.262\n",
      "INFO:tensorflow:loss = 0.006802064, step = 40601 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.15\n",
      "INFO:tensorflow:loss = 0.028065542, step = 40701 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.26\n",
      "INFO:tensorflow:loss = 0.01759904, step = 40801 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.255\n",
      "INFO:tensorflow:loss = 0.03759378, step = 40901 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.487\n",
      "INFO:tensorflow:loss = 0.004465416, step = 41001 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.15\n",
      "INFO:tensorflow:loss = 0.021791099, step = 41101 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.146\n",
      "INFO:tensorflow:loss = 0.008244343, step = 41201 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.49\n",
      "INFO:tensorflow:loss = 0.025542527, step = 41301 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.821\n",
      "INFO:tensorflow:loss = 0.0032995811, step = 41401 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.491\n",
      "INFO:tensorflow:loss = 0.011259282, step = 41501 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.487\n",
      "INFO:tensorflow:loss = 0.0023182216, step = 41601 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.146\n",
      "INFO:tensorflow:loss = 0.018243609, step = 41701 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.148\n",
      "INFO:tensorflow:loss = 0.0033015672, step = 41801 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.264\n",
      "INFO:tensorflow:loss = 0.020873588, step = 41901 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.144\n",
      "INFO:tensorflow:loss = 0.021698033, step = 42001 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.149\n",
      "INFO:tensorflow:loss = 0.0054197093, step = 42101 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.145\n",
      "INFO:tensorflow:loss = 0.025221609, step = 42201 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.259\n",
      "INFO:tensorflow:loss = 0.014771507, step = 42301 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.271\n",
      "INFO:tensorflow:loss = 0.001106798, step = 42401 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.26\n",
      "INFO:tensorflow:loss = 0.007871269, step = 42501 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.259\n",
      "INFO:tensorflow:loss = 0.012853094, step = 42601 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.264\n",
      "INFO:tensorflow:loss = 0.032667078, step = 42701 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.821\n",
      "INFO:tensorflow:loss = 0.021290539, step = 42801 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.262\n",
      "INFO:tensorflow:loss = 0.006813436, step = 42901 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.145\n",
      "INFO:tensorflow:loss = 0.012063965, step = 43001 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.148\n",
      "INFO:tensorflow:loss = 0.0029838558, step = 43101 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.143\n",
      "INFO:tensorflow:loss = 0.019757507, step = 43201 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.151\n",
      "INFO:tensorflow:loss = 0.016788803, step = 43301 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.262\n",
      "INFO:tensorflow:loss = 0.0036506783, step = 43401 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.491\n",
      "INFO:tensorflow:loss = 0.011238072, step = 43501 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.137\n",
      "INFO:tensorflow:loss = 0.0009907125, step = 43601 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.153\n",
      "INFO:tensorflow:loss = 0.013894416, step = 43701 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.487\n",
      "INFO:tensorflow:loss = 0.004377133, step = 43801 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.144\n",
      "INFO:tensorflow:loss = 0.002280333, step = 43901 (0.120 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 44000 into C:\\Users\\ud803\\AppData\\Local\\Temp\\tmp6h5elv9b\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.006469466.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier at 0x23f3e33e648>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [tf.feature_column.numeric_column(\"X\", shape=[28 * 28])]\n",
    "dnn_clf = tf.estimator.DNNClassifier(hidden_units=[300,100], n_classes=10,\n",
    "                                     feature_columns=feature_cols)\n",
    "\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_train}, y=y_train, num_epochs=40, batch_size=50, shuffle=True)\n",
    "dnn_clf.train(input_fn=input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-22T14:14:25Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From C:\\Users\\ud803\\Anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ud803\\AppData\\Local\\Temp\\tmpaydiz5t0\\model.ckpt-44000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-22-14:14:25\n",
      "INFO:tensorflow:Saving dict for global step 44000: accuracy = 0.9807, average_loss = 0.10352209, global_step = 44000, loss = 13.104063\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 44000: C:\\Users\\ud803\\AppData\\Local\\Temp\\tmpaydiz5t0\\model.ckpt-44000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9807,\n",
       " 'average_loss': 0.10352209,\n",
       " 'loss': 13.104063,\n",
       " 'global_step': 44000}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_test}, y=y_test, shuffle=False)\n",
    "eval_results = dnn_clf.evaluate(input_fn=test_input_fn)\n",
    "eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "내부를 들여다보면 `DNNClassifier` 클래스가 `ReLU` 활성화 함수를 기반으로 한 뉴런 층을 만든다.\n",
    "\n",
    "출력층은 소프트맥스 함수고 비용 함수는 크로스 엔트로피이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 텐서플로의 저수준 API로 심층 신경망 훈련하기\n",
    "\n",
    "네트워크의 구조를 더 상세히 제어하고 싶다면 텐서플로의 저수준 파이썬 API가 나을지도 모른다.\n",
    "\n",
    "이 절에서는 저수준 API로 이전과 같은 모델을 만들고 MNIST 데이터셋에서 훈련하기 위해 미니배치 경사 하강법을 구현해본다.\n",
    "\n",
    "첫 번째 스텝은 텐서플로 계산 그래프를 만드는 구성 단계이고, 두 번째 스텝은 실제로 이 그래프를 실행해 모델을 훈련시키는 실행 단계이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 구성 단계\n",
    "\n",
    "먼저 입력과 출력 크기를 지정하고 은닉층의 뉴런 수를 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28*28 #MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런 다음 9장에서처럼 플레이스홀더 노드를 사용해 훈련 데이터와 타깃을 표현한다.\n",
    "\n",
    "X의 크기는 일부분만 정의되는데, 우리가 아는 것은 '첫 번째 차원을 따라 샘플이 있고 두 번째 차원을 따라 특성이 있는' 2D 텐서 (즉, 행렬)라는 점이다.\n",
    "\n",
    "특성의 수는 28x28 이지만 아직 훈련 배치에 몇 개의 샘플이 포함될지 모른다. 그래서 X의 크기는 (None, n_inputs)가 된다.\n",
    "\n",
    "비슷하게 y도 샘플당 하나인 1차원 텐서라는 것은 알지만, 지금 시점엔 훈련 배치의 크기를 알 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 두 개의 은닉층과 하나의 출력층을 만들어야 한다. 두 은닉층은 거의 같고 연결된 입력과 뉴런 수만 다르다.\n",
    "\n",
    "출력층도 매우 비슷한데 ReLU 대신 소프트맥스를 사용한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs + n_neurons)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"kernel\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\")\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        if activation:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드를 한 줄씩 살펴보자.\n",
    "\n",
    "- 먼저 층 이름으로 범위를 만든다. 여기에 이 층에서 필요한 모든 계산 노드가 포함된다. 꼭 필요한 줄은 아니지만 노드가 잘 정리되어 있으면 텐서보드에서 보기가 쉽다.\n",
    "- 입력 행렬의 크기에서 두 번째 차원을 사용해 입력 특성의 수를 구한다.\n",
    "- 다음 세 줄은 가중치 행렬을 담을 W 변수를 만든다. (종종 커널이라고도 부른다.) 이 행렬은 각 입력과 각 뉴런 사이의 모든 연결 가중치를 담고 있는 2D 텐서이다. 그러므로 크기는 (n_inputs, n_neurons)가 된다. 이 행렬은 표준편차를 따라 절단 정규 분포를 사용해 무작위로 초기화된다. 이 표준편차를 사용하면 알고리즘이 훨씬 빠르게 수렴한다. **경사 하강법 알고리즘이 중단되지 않도록 대칭성을 피하기 위해 모든 은닉층의 가중치는 무작위로 초기화하는 것이 중요하다.**\n",
    "- 다음 줄은 뉴런마다 하나의 편향을 갖도록 변수 b를 만들고 0으로 초기화한다. (여기서는 대칭 문제가 없다.)\n",
    "- 그런 다음 Z = XW + b를 계산하기 위한 그래프를 만든다. 이 벡터화된 구현은 층에 있는 모든 뉴런과 배치에 있는 모든 샘플에 대해 입력에 대한 가중치 합에 편향을 더하는 계산을 효율적으로 한 번에 수행한다. XW의 결과인 2D 행렬에 열의 개수와 같은 1D 배열을 더하면 모든 행에 1D 배열이 더해지게 되는데, 이를 **브로드캐스팅**이라고 한다.\n",
    "- 마지막으로 activation 함수가 지정되어 있으면 활성화가 적용된 값을 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\", activation=tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\", activation=tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서도 이름 범위를 사용해 정리했는데, `logits`는 소프트맥스 활성화 함수로 들어가기 직전의 신경망 출력이 된다.\n",
    "\n",
    "최적화 작업이 있기 때문에 소프트맥스 계산은 나중에 처리한다.\n",
    "\n",
    "예상했겠지만 텐서플로에는 표준 신경망 층을 만드는 편리한 함수가 많이 있다. 그래서 앞에서처럼 따로 `neuron_layer()` 함수를 정의할 필요는 없다.\n",
    "\n",
    "텐서플로의 `tf.layers.dense()` 함수는 모든 입력이 은닉층에 있는 모든 뉴런과 연결된 완전 연결 층 fully connected layer를 만든다.\n",
    "\n",
    "이 함수는 적절한 초기화 방식을 사용해 kernel과 bias라는 이름으로 가중치와 편향 변수를 만든다.\n",
    "\n",
    "그리고 `activation` 매개변수로 활성화 함수를 지정할 수 있다. `dense` 함수를 사용하도록 바꾸면 아래와 같이 쓸 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-068651d8eb20>:2: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\", activation=tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name=\"hidden2\", activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 신경망 모델이 준비되었으니 훈련에 사용할 비용 함수를 정의해야 한다. 소프트맥스 회귀에서처럼 크로스 엔트로피를 사용한다.\n",
    "\n",
    "앞서 이야기한 것처럼 크로스 엔트로피는 모델이 타깃 클래스에 대해 낮은 확률을 추정하지 않도록 제약을 가한다. 텐서플로는 크로스 엔트로피를 계산하기 위한 함수를 여러 개 제공한다.\n",
    "\n",
    "여기서는 `sparse_softmax_cross_entropy_with_logits()` 함수를 사용한다. 이 함수는 로짓(즉, 소프트맥스 활성화 함수로 들어가기 전의 네트워크 출력)을 기반으로 크로스 엔트로피를 계산한다.\n",
    "\n",
    "그리고 0에서 9 사이의 정수로 된 레이블을 기대한다. 이 함수는 각 샘플에 대한 크로스 엔트로피를 담은 1D 텐서를 반환하고, 텐서플로의 `reduce_mean()` 함수를 사용하여 모든 샘플에 대한 크로스 엔트로피 평균을 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 신경망 모델과 비용 함수가 준비되었으니 `GradientDescentOptimizer`를 사용해 이 비용 함수를 최소화시키도록 모델 파라미터를 조정해나갈 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구성 단계에서 중요한 마지막 단계는 모델을 평가하는 방법을 지정하는 것이다. 여기서는 간단하게 정확도를 사용해 성능을 측정한다.\n",
    "\n",
    "먼저 샘플마다 가장 큰 로짓이 타깃 클래스에 해당하는지 여부를 확인해 신경망의 예측이 맞는지 결정한다.\n",
    "\n",
    "이를 위해 `in_top_k()` 함수를 사용하는데, 이는 불린 값으로 채워진 1D 텐서를 반환하므로 실수형으로 변환하고 평균을 낸다.\n",
    "\n",
    "이 값이 신경망의 정체 정확도이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 통상적으로 모든 변수를 초기화하는 노드를 만들고 훈련된 모델 파라미터를 디스크에 저장하기 위한 Saver 객체를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이것으로 구성 단계를 마쳤다. 40줄 미만의 코드이지만 매우 많은 것이 담겨있다.\n",
    "\n",
    "- 입력과 출력을 위한 플레이스홀더를 만들었고,\n",
    "- 뉴런의 층을 구성하는 함수를 만들었고,\n",
    "- 이 함수를 사용해 심층 신경망을 생성했다.\n",
    "- 비용 함수와 옵티마이저를 생성하고 마지막에 성능 지표까지 정의했다.\n",
    "\n",
    "이제 실행을 할 차례이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 실행 단계\n",
    "\n",
    "이 단계는 짧고 간단하다. 먼저 데이터셋을 불러들인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 실행시킬 에포크 횟수와 미니배치 크기를 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 모델을 훈련시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 배치 데이터 정확도: 0.96 검증 세트 정확도: 0.903\n",
      "1 배치 데이터 정확도: 0.92 검증 세트 정확도: 0.9222\n",
      "2 배치 데이터 정확도: 0.94 검증 세트 정확도: 0.9318\n",
      "3 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9368\n",
      "4 배치 데이터 정확도: 0.96 검증 세트 정확도: 0.942\n",
      "5 배치 데이터 정확도: 0.94 검증 세트 정확도: 0.9496\n",
      "6 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.953\n",
      "7 배치 데이터 정확도: 0.96 검증 세트 정확도: 0.9572\n",
      "8 배치 데이터 정확도: 0.94 검증 세트 정확도: 0.9594\n",
      "9 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9618\n",
      "10 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.966\n",
      "11 배치 데이터 정확도: 0.96 검증 세트 정확도: 0.9666\n",
      "12 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9672\n",
      "13 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9682\n",
      "14 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.969\n",
      "15 배치 데이터 정확도: 0.96 검증 세트 정확도: 0.9714\n",
      "16 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9712\n",
      "17 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9724\n",
      "18 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9746\n",
      "19 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.975\n",
      "20 배치 데이터 정확도: 0.96 검증 세트 정확도: 0.976\n",
      "21 배치 데이터 정확도: 0.96 검증 세트 정확도: 0.9746\n",
      "22 배치 데이터 정확도: 0.96 검증 세트 정확도: 0.9734\n",
      "23 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9772\n",
      "24 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9762\n",
      "25 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.976\n",
      "26 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9766\n",
      "27 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9776\n",
      "28 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9798\n",
      "29 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9782\n",
      "30 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9774\n",
      "31 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9788\n",
      "32 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9784\n",
      "33 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9782\n",
      "34 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9792\n",
      "35 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9792\n",
      "36 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9786\n",
      "37 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9786\n",
      "38 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.98\n",
      "39 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9794\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"배치 데이터 정확도:\", acc_batch, \"검증 세트 정확도:\", acc_valid)\n",
    "        \n",
    "    save_path = saver.save(sess, \"models/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 코드는 텐서플로의 세션을 열고 init 노드를 실행해서 모든 변수를 초기화한다.\n",
    "\n",
    "그런 다음 바깥쪽 훈련 루프를 실행한다. 매 에포크에서 훈련 데이터의 크기를 미니배치 크기로 나눈 횟수만큼 반복한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 신경망 사용하기\n",
    "\n",
    "신경망을 훈련시키고 나면 이를 사용해 예측을 만들 수 있다. 이때 구성 단계는 그대로 재사용할 수 있지만 실행 단계는 다음과 같이 바꿔야 한다."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"models/my_model_final.ckpt\")\n",
    "    Z = logits.eval(feed_dict={X: X_new})\n",
    "    y_pred = np.argmax(Z, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 모델 파라미터를 읽어들이고, 훈련 데이터와 같은 스케일로 조정한다.\n",
    "\n",
    "그런 다음 logits 노드를 평가한다. 모든 클래스에 대한 추정 확률을 알고 싶다면 로짓에 softmax() 함수를 적용하면 된다.\n",
    "\n",
    "하지만 어떤 클래스 하나를 예측하는 것이라면 간단하게 로짓 값이 가장 큰 클래스를 선택하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
