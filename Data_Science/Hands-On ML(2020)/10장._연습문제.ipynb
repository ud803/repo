{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. 생략\n",
    "### Q2. 고전적입 퍼셉트론 (퍼셉트론 훈련 알고리즘으로 훈련된 단일 TLU)보다 로지스틱 회귀 분류기가 일반적으로 선호되는 이유는?\n",
    "\n",
    "구체적인 확률을 구할 수 있기 때문에\n",
    "\n",
    "-> 고전적인 퍼셉트론은 데이터셋이 선형적으로 구분될 때만 수렴하고 클래스 확률을 추정할 수 없다. 반대로 로지스틱 회귀 분류는 데이터가 선형적으로 구분되지 못해도 좋은 솔루션으로 수렴하고 클래스 확률을 추정한다. 퍼셉트론의 활성화 함수를 로지스틱 활성화 함수로 바꾸고, 경사 하강법을 사용하여 훈련시키면 로지스틱 회귀 분류기와 동일하게 된다.\n",
    "\n",
    "### Q3. 왜 초창기의 다층 퍼셉트론을 훈련시킬 때 로지스틱 활성화 함수가 핵심 요소였나요?\n",
    "\n",
    "계단 함수는 평편하여 그래디언트가 없지만, 로지스틱 함수는 모든 지점에서 그래디언트가 존재하기 때문이다. -> 역전파 용이\n",
    "\n",
    "-> 로지스틱 활성화 함수의 도함수는 어디에서나 0이 아니어서 경사 하강법이 항상 경사를 따라 이동할 수 있기 때문이다.\n",
    "\n",
    "### Q4. 유명한 활성화 함수 네 가지는?\n",
    "\n",
    "로지스틱 함수 / ReLU / Step / Hyperbolic Tangent\n",
    "\n",
    "### Q5. 10개의 통과 뉴런으로 된 입력층, 50개의 뉴런으로 된 은닉층, 그리고 3개의 뉴런으로 된 출력층으로 구성된 다층 퍼셉트론이 있다고 가정해보자. 모든 뉴런은 ReLU 활성화 함수를 사용할 때 아래 문제를 풀어라.\n",
    "\n",
    "- 입력 행렬 X의 크기는? m(데이터 개수) X 10\n",
    "- 은닉층의 가중치 벡터 $W_h$와 편향 벡터 $b_h$의 크기는? 10 // 크기는 10X50, 길이는 50\n",
    "- 출력층의 가중치 벡터 $W_o$와 편향 벡터 $b_o$의 크기는? 3 // 크기는 50X3, 길이는 3\n",
    "- 네트워크의 출력 행렬 Y의 크기는? 1 // 크기는 m X 3\n",
    "- X, $W_h$, $b_h$, $W_o$, $b_o$의 함수로 네트워크의 출력 행렬 Y를 계산하는 씩을 써보세요. \n",
    "\n",
    "### Q6. 스팸 메일을 분류하기 위해서는 출력층에 몇 개의 뉴런이 필요할까? 출력층에 어떤 활성화 함수를 사용해야 할까? MNIST 문제라면 출력층에 어떤 활성화 함수를 사용하고 뉴런은 몇 개가 필요할까? 2장에서 본 주택 가격용 네트워크에 대해 같은 질문의 답을 찾아보라.\n",
    "\n",
    "- 스팸 = 2개 / 활성화 함수는 로지스틱/스텝함수 // 출력층에 하나의 뉴런만 필요하다! 에를 들어 이메일이 스팸일 확률을 출력하면 된다. 일반적으로 로지스틱 활성화 함수를 사용한다.\n",
    "- MNIST = 소프트맥스 활성화 함수 / 출력층에 10개의 뉴런이 필요 (0~9)\n",
    "- 주택 가격용 네트워크 = 1개의 뉴런 / ReLU 또는 Tang 함수 // 출력층에 활성화 함수가 없는 출력 뉴런 하나가 필요하다.\n",
    "\n",
    "### Q7. 역전파란 무엇이고 어떻게 작동하나요? 역전파와 후진 모드 자동 미분의 차이점은?\n",
    "\n",
    "역전파란 오차를 뉴런의 가중치에 따라 거꾸로 나눠주어 가중치를 조정하는 것. 차이점은 없다..? (XXX)\n",
    "\n",
    "역전파는 그래디언트 계산과 경사 하강법 스텝을 여러 번 수행하여 인공 신경망을 훈련시키는 전체 프로세스를 의미한다. 이와 다르게 후진 자동 미분은 그래디언트를 효과적으로 계산하는 하나의 기법으로 역전파에서 사용된다.\n",
    "\n",
    "\n",
    "### Q8. 다층 퍼셉트론에서 조정할 수 있는 하이퍼파라미터를 모두 나열해보라. 훈련 데이터에 다층 퍼셉트론이 과대적합되었다면 이를 해결하기 위해 하이퍼파라미터를 어떻게 조정해야 할까?\n",
    "\n",
    "모른다.\n",
    "\n",
    "은닉층 수, 각 은닉층의 뉴런 수, 각 은닉층과 출력층에서 사용하는 활성화 함수\n",
    "\n",
    "\n",
    "### Q9. 깊은 다층 퍼셉트론을 MNIST 데이터셋에 훈련시키고 98% 정확도를 얻을 수 있는지 확인해보라. 9장의 마지막 연습문제에서와 같이 모든 부가 기능을 추가해보라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ud803\\Anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ud803\\Anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ud803\\Anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ud803\\Anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ud803\\Anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ud803\\Anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NumericColumn(key='X', shape=(784,), default_value=None, dtype=tf.float32, normalizer_fn=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.feature_column.numeric_column(\"X\", shape=[28 * 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28*28 #MNIST\n",
    "n_hidden1 = 100\n",
    "n_hidden2 = 100\n",
    "n_hidden3 = 100\n",
    "n_hidden4 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-aafaf553bb5e>:2: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\Users\\ud803\\Anaconda3\\envs\\hands_on_ml\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\", activation=tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name=\"hidden2\", activation=tf.nn.relu)\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, name=\"hidden3\", activation=tf.nn.relu)\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, name=\"hidden4\", activation=tf.nn.relu)\n",
    "\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 배치 데이터 정확도: 0.86 검증 세트 정확도: 0.9008\n",
      "1 배치 데이터 정확도: 0.92 검증 세트 정확도: 0.92\n",
      "2 배치 데이터 정확도: 0.96 검증 세트 정확도: 0.9366\n",
      "3 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9484\n",
      "4 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9536\n",
      "5 배치 데이터 정확도: 0.92 검증 세트 정확도: 0.9548\n",
      "6 배치 데이터 정확도: 0.94 검증 세트 정확도: 0.9556\n",
      "7 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9606\n",
      "8 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9626\n",
      "9 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9622\n",
      "10 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9638\n",
      "11 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9684\n",
      "12 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9704\n",
      "13 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9696\n",
      "14 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9718\n",
      "15 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9712\n",
      "16 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9716\n",
      "17 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9742\n",
      "18 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9726\n",
      "19 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9736\n",
      "20 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.973\n",
      "21 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9752\n",
      "22 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9758\n",
      "23 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9744\n",
      "24 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.977\n",
      "25 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9778\n",
      "26 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9766\n",
      "27 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.977\n",
      "28 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.976\n",
      "29 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9758\n",
      "30 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9782\n",
      "31 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9768\n",
      "32 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9758\n",
      "33 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.978\n",
      "34 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.978\n",
      "35 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9754\n",
      "36 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.977\n",
      "37 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9774\n",
      "38 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9778\n",
      "39 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9788\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"배치 데이터 정확도:\", acc_batch, \"검증 세트 정확도:\", acc_valid)\n",
    "        \n",
    "    save_path = saver.save(sess, \"models/chap10_exercise.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
