{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1장. 한 눈에 보는 머신러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 장에서는 머신러닝의 전체 그림을 조망하고 주요 영역과 가장 중요한 랜드마크인 **지도 학습과 비지도학습, 온라인 학습과 배치 학습, 사례 기반 학습과 모델 기반 학습**을 알아본다.\n",
    "\n",
    "또한 모든 데이터 과학자가 알아야 할 여러 기초 개념과 용어를 소개할 것이다. 이 책의 나머지를 제대로 배우기 위해선 1장이 마스터되어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 머신러닝이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝은 데이터로부터 학습하도록 컴퓨터를 프로그래밍하는 과학이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***\"머신러닝은 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야다. \" _아서 사무엘, 1959***\n",
    "\n",
    "> \"Field of study that gives computers the ability to learn without being explicitly programmed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "조금더 공학적인 정의는 아래와 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***\"어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다.\" _톰 미첼, 1997***\n",
    "\n",
    "> \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들어, **스팸 필터**는 스팸 메일 구분법을 배울 수 있는 머신러닝 프로그램이다. 시스템이 학습하는 데 사용하는 샘플을 **훈련 세트(Training Set)**라고 하고 각 훈련 데이터를 **훈련 사례(Training Instance, 혹은 훈련 샘플, Sample)** 이라고 한다. 이 경우, 작업 T는 새로운 메일이 스팸인지 구분하는 것이고, 경험 E는 **훈련 데이터(Training Data)**이며, 성능 측정 P는 직업 정의해야 한다. 예컨대 정확히 분류된 메일의 비율을 P라고 하면, 이는 **정확도(Accuracy)**라고 부르며 분류 작업에서 자주 쓰이는 성능 기준이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 왜 사용하는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전통적인 프로그래밍 기법으로 스팸 필터를 구상해보자.\n",
    "\n",
    "1. 스팸에서 패턴을 찾아낸다. \n",
    "2. 발견한 각 패턴을 감지하는 알고리즘을 작성하여 그렇게 분류하도록 한다.\n",
    "3. 프로그램을 테스트하고 충분한 성능이 나올 때까지 1, 2를 반복한다.\n",
    "\n",
    "이러한 방식에서는, 스팸의 문구가 바뀐다면 알고리즘에서 제외 리스트도 바꿔주어야 한다. 하지만 머신러닝 기반의 스팸 필터에서는 이를 자동으로 인식하고 스팸으로 분류하게 된다.\n",
    "\n",
    "이렇게 머신러닝 기술을 적용해서 대용량의 데이터를 분석하면 숨겨진 패턴을 발견할 수 있는데, 이를 **데이터 마이닝(Data Mining)**이라고 한다.\n",
    "\n",
    "요약하면 머신러닝은 아래의 분야에 뛰어나다.\n",
    "\n",
    "- 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제\n",
    "- 전통적인 방식으로는 전혀 해결 방법이 없는 복잡한 문제\n",
    "- 유동적인 환경\n",
    "- 복잡한 문제와 대량의 데이터에서 통찰 얻기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 머신러닝 시스템의 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝 시스템의 종류는 굉장히 많으므로 다음을 기준으로 넓은 범주에서 분류하면 도움이 된다.\n",
    "\n",
    "- 사람의 감독 하에 훈련하는지 아닌지 (지도, 비지도, 준지도, 강화 학습)\n",
    "- 실시간으로 점진적인 학습을 하는지 아닌지 (온라인 학습, 배치 학습)\n",
    "- 단순하게 알고 있는 데이터 포인트와 새 데이터 포인트를 비교하는 것인지 아니면 훈련 데이터셋에서 과학자들처럼 패턴을 발견하여 예측 모델을 만드는지 (사례 기반 학습과 모델 기반 학습)\n",
    "\n",
    "**이 범주들은 서로 배타적이지 않으며, 얼마든 연결될 수 있다는 것에 유의하자.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 지도 학습과 비지도 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시스템을 '학습하는 동안의 감독 형태나 정보량'에 따라 분류해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 지도 학습, Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지도 학습에서는 알고리즘에 주입하는 훈련 데이터에 **레이블(label)**이라는 원하는 답이 포함된다.\n",
    "\n",
    "- **분류(Classification)**가 전형적인 지도 학습 작업이며, 아까 나온 스팸 필터가 그 예이다.\n",
    "- **회귀(Regression)**는 **예측 변수(Predictor Variable)**라 부르는 **특성(Feature)를** 사용해 중고차 가격 같은 **타겟(Target)** 수치를 예측하는 것이다.\n",
    "\n",
    "일부 회귀 알고리즘은 분류에 사용할 수도 있고, 반대의 경우도 있다. 예를 들어 분류에 널리 쓰이는 **로지스틱 회귀**는 데이터가 어떤 클래스에 속할 확률을 출력한다.\n",
    "\n",
    "대표적인 지도 학습의 알고리즘은 다음과 같다.\n",
    "\n",
    "- k-최근접 이웃, k-Nearest Neighbor\n",
    "- 선형 회귀, Linear Regression\n",
    "- 로지스틱 회귀, Logistic Regression\n",
    "- 서포트 벡터 머신, Support Vector Machine(SVM)\n",
    "- 결정 트리와 랜덤 포레스트, Decision Tree & Random Forest\n",
    "- 신경망, Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Tip. 머신러닝에서 **속성(Attribute)**은 데이터 타입(예를 들면 주행거리)을 말한다. **특성**은 문맥에 따라 여러 의미를 갖지만 일반적으로 속성과 값이 합쳐진 것을 의미한다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비지도 학습, Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비지도 학습에는 말 그대로 훈련 데이터에 레이블이 없다. 시스템이 아무런 도움 없이, 사전 정보 없이 학습하는 것이다.\n",
    "\n",
    "대표적인 비지도 학습 알고리즘은 아래와 같다.\n",
    "\n",
    "- 군집, Clustering\n",
    "    - k-평균, K-means\n",
    "    - 계층 군집 분석, Hierarchical Cluster Analysis (HCA)\n",
    "    - 기댓값 최대화, Expectation Maximization\n",
    "- 시각화와 차원 축소, Visualization & Dimensionality Reduction\n",
    "    - 주성분 분석, Principal Component Analysis(PCA)\n",
    "    - 커널 PCA\n",
    "    - 지역적 선형 임베딩, Locally-Linear Embedding (LLE)\n",
    "    - t-SNE, t-distributed Stochastic Neighbor Embedding\n",
    "- 연관 규칙 학습, Association Rule Learning\n",
    "    - 어프라이어리, Apriori\n",
    "    - 이클렛, Eclat\n",
    "\n",
    "예를 들어, 블로그 방문자에 대한 데이터가 많이 있어 비슷한 그룹으로 묶기 위해 군집 알고리즘을 사용한다고 하자. 하지만 바움ㄴ자가 어떤 그룹에 속하는지 알려줄 수 있는 데이터 값은 없다. 계층 군집을 사용한다면 각 그룹을 더 작은 그룹으로 세분화할 수 있다. \n",
    "\n",
    "또한 정보를 최대한 잃지 않으면서 데이터를 간소화하는 **차원 축소**는, 상관관계가 있는 여러 특성들을 하나로 합치는 방법을 사용한다. 이를 **특성 추출(Feature Extraction)**이라고 한다. 이렇게 차원 축소를 하게 되면 실행 속도도 훨씬 빨라지고 디스크와 메모리를 차지하는 공간도 줄게 된다.\n",
    "\n",
    "**이상치 탐지(Anomaly Detection)**은 정상 샘플로 훈련된 후, 새로운 샘플이 정상 데이터인지 혹은 이 상치인지 판단한다.\n",
    "\n",
    "또한 **연관 규칙 학습**은 대량의 데이터에서 특성 간의 흥미로운 관계를 찾고자 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **준지도 학습, Semisupervised Learning**\n",
    "\n",
    "어떤 알고리즘은 레이블이 일부만 있는 데이터를 다룰 수 있다. 이를 준지도 학습이라고 한다.\n",
    "\n",
    "구글 포토 호스팅 서비스가 좋은 예인데, 가족 사진을 모두 업로드하면 사람 A와 B가 어떤 사진에 나와있는지 자동으로 인식한다. 이는 비지도 학습(군집)이며, 이제 시스템에 필요한 것은 이 사람들이 누구인가 하는 정보이다. 사람마다 레이블이 하나씩만 주어지면 사진에 있는 모든 사람의 이름을 알 수 있고, 편리하게 사진을 찾을 수 있다.\n",
    "\n",
    "대부분의 준지도 학습 알고리즘은 비지도와 지도 학습의 조합으로 이루어진다. 예를 들어, **심층 신뢰 신경망(Deep Belief Network, DBN)**은 여러 겹으로 쌓은 **제한된 볼츠만 머신(Restricted Boltzmann Machine, RBM)**이라 불리는 비지도 학습에 기초한다. \n",
    "\n",
    "### **강화 학습, Reinforcement Learning**\n",
    "\n",
    "강화학습은 매우 다른 종류의 알고리즘이다. 학습하는 시스템을 **에이전트(Agent)**라고 부르며, **환경(Environment)**을 관찰해서 **행동(Action)**을 실행하고 그 결과로 **보상(Reward)**이나 부정적인 보상인 **벌점(Penalty)**를 받는다. 시간이 지나면서 가장 큰 보상을 얻기 위해 **정책(Policy)**이라고 부르는 최상의 전략을 스스로 학습하게 된다.\n",
    "\n",
    "딥마인드의 알파고가 그 예이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 지도 학습과 비지도 학습\n",
    "\n",
    "머신러닝 시스템을 분류하는 또 다른 기준은 입력 데이터의 스트림으로부터 점진적으로 학습할 수 있는지 여부이다.\n",
    "\n",
    "### **배치 학습, Batch Learning**\n",
    "\n",
    "배치 학습에서는 시스템이 점진적으로 학습할 수 없고, 가용한 데이터를 모두 사용하여 훈련시켜야 한다. 이 방식은 자원과 시간을 많이 소모하므로 보통 오프라인에서 수행된다. 먼저 시스템을 훈련시킨 뒤, 다음 제품 시스템에 적용하면 더 이상의 학습은 없이 실행된다. **오프라인 학습(Offline Learning)** 이라고도 한다.\n",
    "\n",
    "새로운 데이터에 대해 학습하기 위해서는 새로운 데이터와 기존 데이터를 포함한 전체 데이터를 이용하여 시스템의 새로운 버전을 처음부터 다시 훈련해야 한다. 따라서 시스템이 빠르게 변하는 데이터에 적응해야 한다면 더 능동적인 방법이 필요하다. 또한 자원이 제한된 시스템(스마트폰이나 화성 탐사 로버)이 스스로 학습해야 할 때 학습을 위해 매일 몇 시간씩 많은 자원을 사용하면 심각한 문제를 일으키게 된다.\n",
    "\n",
    "### **온라인 학습, Online Learning**\n",
    "\n",
    "온라인 학습에서는 데이터를 순차적으로 한 개씩 또는 **미니 배치(mini-batch)**라 부르는 작은 묶음 단위로 주입하여 시스템을 훈련시킨다. 매 학습 단계가 빠르고 비용이 적게 들어 시스템은 데이터가 도착하는 대로 즉시 학습할 수 있다. 온라인 학습 시스템이 새로운 데이터 샘플을 학습하면 학습이 끝난 데이터는 더 이상 필요하지 않으므로 버리면 된다. (이전 상태로 되돌릴 수 있도록 데이터를 재사용하기위해 보관할 필요가 없다면) 따라서 많은 공간을 절약할 수 있게 된다.\n",
    "\n",
    "온라인 학습 시스템에서 중요한 파라미터 하나는, 변화하는 데이터에 얼마나 빠르게 적응할 것인지 이다. 이를 **학습률(Learning Rate)**이라고 한다. 높게 하면 시스템이 데이터에 빠르게 적응하지만 예저 데이터를 금방 잊어버리고, 낮으면 시스템의 관성이 더 커져 느리가 학습한다. \n",
    "\n",
    "## 3.3 사례 기반 학습과 모델 기반 학습\n",
    "\n",
    "일반화에 따라 분류될 수 있다. 대부분의 머신러닝 작업은 예측을 만드는 것인데, 주어진 훈련 데이터로 학습하지만 **훈련 데이터에서는 본 적 없는 새로운 데이터**로 일반화되어야 한다는 뜻이다. 훈련 데이터에서의 높은 성능도 좋지만, 진짜 목표는 새로운 샘플에 잘 작동하는 모델이다.\n",
    "\n",
    "### **사례 기반 학습, Instance-based Learning**\n",
    "\n",
    "가장 간단한 형태의 학습은 단순히 기억하는 것이다. 스팸 필터를 이렇게 만들면 사용자가 스팸이라고 지정한 메일과 동일한 모든 메일을 스팸으로 분류한다. 최악은 아니지만 최선의 방법도 아니다.\n",
    "\n",
    "그 대신, 스팸 메일과 \"유사한\" 메일을 구분하도록 스팸 필터를 만들 수 있다. 두 메일 사이의 **유사도(Similarity)**를 측정해야 하는데, 예를 들어 공통으로 포함된 단어의 수를 세는 방법 등이 있다.\n",
    "\n",
    "이를 사례 기반 학습이라고 하고, 시스템이 사례를 기억함으로써 학습시키는 것이다. 그리고 유사도 측정을 사용해 새로운 데이터에 일반화한다.\n",
    "\n",
    "### **모델 기반 학습, Model-based Learning**\n",
    "\n",
    "샘플들의 모델을 만들어 예측에 사용하는 방법도 있다. 이를 모델 기반 학습이라고 한다.\n",
    "\n",
    "예를 들어 돈이 사람을 행복하게 만드는지 알아본다고 가정해보자. 데이터를 통해 살펴보면 데이터들은 흩어져 있지만 GDP가 증가할수록 삶의 만족도가 거의 선형으로 올라간다는 것을 알 수 있다. 따라서 1인당 GDP의 선형 함수로 삶의 만족도를 모델링 할 수 있다. 이 단계를 **모델 선택(Model Selection)**이라고 한다. 이는 1인당 GDP라는 **특성** 하나를 가진 삶의 만족도에 대한 **선형 모델(Linear Model)**이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$삶의 만족도 = \\theta_0 + \\theta_1 * GDP_{1인당}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 모델은 두 개의 모델 파라미터를 갖는다. 그럼 여기서 나올 질문은, 어떤 파라미터의 값들이 가장 좋은 값일까? 이다. 이 질문에 답하기 위해서는 **측정 지표**를 정해야 한다. \n",
    "\n",
    "모델이 얼마나 좋은지 측정하는 **효용 함수(Utility Function)** 또는 **적합도 함수(Fitness Function)**를 정의하거나, 얼마나 나쁜지 측정하는 **비용 함수(Cost Function)**을 정의할 수 있다. \n",
    "\n",
    "선형 회귀에서는 보통 선형 모델의 예측과 훈련 데이터 사이의 거리를 재는 비용 함수를 사용한다. 이 거리를 최소화하는 것이 목표이다.\n",
    "\n",
    "알고리즘에 훈련 데이터를 공급하면, 데이터에 가장 잘 맞는 선형 모델의 파라미터를 찾게 되고, 이를 모델을 훈련시킨다고 말한다. \n",
    "\n",
    "지금까지의 작업을 요약하면 다음과 같다.\n",
    "\n",
    "- 데이터를 분석한다.\n",
    "- 모델을 선택한다.\n",
    "- 훈련 데이터로 모델을 훈련시킨다. (학습 알고리즘이 비용 함수를 최소화하는 모델 파라미터를 찾는다.)\n",
    "- 새로운 데이터에 모델을 적용해 예측하고(보통 **추론Inference**이라고 한다.), 잘 일반화되길 기대한다.\n",
    "\n",
    "# 4. 머신러닝의 주요 도전 과제\n",
    "\n",
    "머신러닝에서 신경써야 할 부분들은 무엇일까?\n",
    "\n",
    "### **충분하지 않은 양의 훈련 데이터**\n",
    "\n",
    "대부분의 머신러닝 알고리즘이 잘 작동하려면 데이터가 많아야 한다. 아주 간단한 문제에서조차도 수천 개의 데이터가 필요하고 이미지나 음성 인식 같은 복잡한 문제라면 수백만 개가 필요할지도 모른다. \n",
    "\n",
    "데이터의 효과는 몇몇 논문에서 입증되었다. 즉, 알고리즘보다 데이터의 양 그 자체가 더 중요할 수 있다는 뜻이다.\n",
    "\n",
    "- 2001. Scaling to Very Very Large Corpora for Natural Language Disambiguation\n",
    "\n",
    "[https://www.aclweb.org/anthology/P01-1005/](https://www.aclweb.org/anthology/P01-1005/)\n",
    "\n",
    "- 2009. The Unreasonable Effectiveness of Data\n",
    "\n",
    "[http://static.googleusercontent.com/media/research.google.com/fr//pubs/archive/35179.pdf](http://static.googleusercontent.com/media/research.google.com/fr//pubs/archive/35179.pdf)\n",
    "\n",
    "### **대표성 없는 훈련 데이터**\n",
    "\n",
    "일반화가 잘 되려면 일반화하기 원하는 새로운 사례를 훈련 데이터가 잘 대표해야 한다. \n",
    "\n",
    "일반화하려는 사례들을 대표하는 훈련 세트를 사용하는 것이 매우 중요하지만, 이게 생각보다 어려울 때가 많다. 샘플이 작으면 **샘플링 잡음(Sampling Noise,** 우연에 의한 대표성 없는 데이터)가 생기고, 매우 큰 샘플도 표본 추출 방법이 잘못되면 **샘플링 편향(Sampling Biase,** 대표성을 띠지 못하는 것)이 생길 수 있다.\n",
    "\n",
    "### **낮은 품질의 데이터**\n",
    "\n",
    "훈련 데이터가 에러, **이상치Outlier,** 잡음으로 가득하다면 데이터 정제를 해야한다.\n",
    "\n",
    "### **관련 없는 특성**\n",
    "\n",
    "성공적인 머신러닝 프로젝트의 핵심 요소는 훈련에 사용할 좋은 특성들을 찾는 것이다. 이 과정을 **특성 공학(Feature Engineering)**이라고 한다.\n",
    "\n",
    "- **특성 선택(Feature Selection)** : 가지고 있는 특성 중에서 훈련에 가장 유용한 특성을 선택한다.\n",
    "- 특성 추출(Feature Extraction) : 특성을 결합하여 더 유용한 특성을 만든다. (축소 알고리즘 같은)\n",
    "- 새로운 데이터를 수집해 새 특성을 만들기.\n",
    "\n",
    "### **훈련 데이터 과대적합**\n",
    "\n",
    "훈련 데이터에 모델이 너무 적합하게 되면 **과대적합(Overfitting)** 문제가 발생한다. 일반성이 떨어진다는 것이다. 심층 신경망 같이 복잡한 모델을 데이터에서 미묘한 패턴을 감지할 수 있지만, 훈련 세트에 잡음이 많거나 데이터셋이 너무 작으면 잡음이 섞인 패턴을 감지하게 된다. \n",
    "\n",
    "보통 이를 해결하는 방법은 다음과 같다.\n",
    "\n",
    "- 파라미터 수가 작은 모델을 선택 (고차원 다항 모델보다는 선형 모델)\n",
    "- 훈련 데이터에 있는 특성 수를 줄이거나, 모델에 제약을 가한다.\n",
    "- 훈련 데이터의 양을 늘리거나 잡음을 줄인다. (데이터 수정과 이상치 제거)\n",
    "\n",
    "모델을 단순하게 하고 과대적합의 위험을 감소시키기 위해 모델에 제약을 가하는 것을 **규제(Regularization)**라고 한다. 앞서 본 선형 모델은 두 개의 파라미터 theta_0과 theta_1을 가지고 있는데, 두 개의 **자유도(Degree of Freedom)**을 갖는 것이나 마찬가지이다. 만약 우리가 theta_1 = 0으로 강제하면, 알고리즘에 한 개의 자유도만 남아 모델 적합이 힘들 것이다.\n",
    "\n",
    "따라서 알고리즘이 theta_1을 수정하도록 허락하되 작은 값을 갖도록 유지시키면 자유도 1과 2 사이에 적절하게 위치하여 올바른 균형을 찾을 수 있다.\n",
    "\n",
    "학습하는 동안 규제할 양은 **하이퍼파라미터(Hyperparameter)**가 결정하는데, 하이퍼파라미터는 모델이 아니라 학습 알고리즘의 파라미터이다. 그래서 학습 알고리즘으로부터 영향을 받지 않으며, 훈련 전에 미리 지정디고, 훈련하는 동안에는 상수로 남아있다. 이를 매우 큰 값으로 지정하면 기울기가 0에 가까운 평편한 모델을 얻겓 되고, 학습 알고리즘이 훈련 데이터에 과대적합될 가능성은 줄어들지만 좋은 모델을 찾기가 힘들어진다.\n",
    "\n",
    "### **훈련 데이터 과소적합**\n",
    "\n",
    "**과소적합(Underfitting)**은 과대적합의 반대로써 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 일어난다. 예를 들어 삶의 만족도에 대한 선형 모델을 과소적합되기 쉽다. \n",
    "\n",
    "과소적합은 주로 아래 방법으로 해결한다.\n",
    "\n",
    "- 모델 파라미터가 더 많은 모델을 선택한다.\n",
    "- 학습 알고리즘에 더 좋은 특성을 제공한다. (특성 공학)\n",
    "- 모델의 제약을 줄인다. (예를 들어 규제 하이퍼파라미터를 감소시킨다.)\n",
    "\n",
    "# 5. 테스트와 검증\n",
    "\n",
    "모델이 새로운 샘플에 얼마나 잘 일반화될지 아는 유일한 방법은 새로운 샘플에 실제로 적용해보는 것이다. 이를 위해 실제 서비스에 모델을 넣고 잘 동작하는지 모니터링하는 방법이 있지만, 모델이 아주 나쁘다면 고객이 불만을 토로할 지도 모른다.\n",
    "\n",
    "더 나은 방법은 훈련 데이터를 **훈련 세트**와 **테스트 세트** 두 개로 나누는 것이다. 훈련 세트를 사용해 모델을 훈련시키고, 테스트 세트를 사용해 모델을 테스트하게 된다. 새로운 샘플에 대한 오류 비율을 **일반화 오차(Generalization Error)** 또는 **외부 샘플 오차(Out-Of-Sample Error)**라고 하며, 테스트 세트에서 모델을 평가함으로써 이 오차에 대한 **추정값(Estimation)**을 얻게 된다.\n",
    "\n",
    "예를 들어, 훈련 오차가 낮지만 일반화 오차가 높다면 이는 모델이 훈련 데이터에 과적합되었다는 뜻이다.\n",
    "\n",
    "모델 평가는 아주 간단한데, 만약 선형 모델과 다항 모델 중 고민하다가, 테스트 세트를 사용해 선형 모델의 일반화가 더 좋았다고 가정해보자. 이제 과대적합을 피하기 위해 규제를 적용하려고 할 때, 하이퍼파라미터 값을 어떻게 선택하면 좋을까?\n",
    "\n",
    "100개의 하이퍼파라미터 값으로 100개의 다른 모델을 훈련시키는 방법이 있는데, 이를 통해 일반화 오차가 가장 낮은 모델을 만드는 최적의 하이퍼파라미터를 찾았다고 생각해보자. 이 모델을 실제 서비스에 투입하면 성능이 좋을까? 그렇지 않다.\n",
    "\n",
    "일반화 오차를 테스트 세트에서 여러 번 측정했으므로 모델과 하이퍼파라미터가 테스트 세트에 최적화된 모델을 만들었기 때문이다.\n",
    "\n",
    "이 문제에 대한 일반적인 해결 방법은 **검증 세트(Validation Set)**라 부르는 두 번째 홀드아웃 세트를 만드는 것이다. 훈련 세트를 사용해 다양한 하이퍼파라미터로 여러 모델을 훈련시키고 검증 세트에서 최상의 성능을 내는 모델과 하이퍼파라미터를 선택한다. 만족스러운 모델을 찾으면 일반화 오차의 추정값을 얻기 위해 테스트 세트로 단 한 번의 최종 테스트를 한다.\n",
    "\n",
    "훈련 데이터에서 검증 세트로 너무 많은 양의 데이터를 뺏기지 않기 위해 일반적으로 **교차 검증(Cross-Validation)** 기법을 사용한다. 훈련 세트를 여러 서브셋으로 나누고 각 모델을 이 서브셋의 조합으로 훈련시키고 나머지 부분으로 검증한다. 모델과 하이퍼파라미터가 선택되면 전체 훈련 데이터를 사용하여 선택한 하이퍼파라미터로 최종 모델을 훈련시키고 테스트 세트에서 일반화 오차를 측정한다.\n",
    "\n",
    "# 6. 연습문제\n",
    "\n",
    "마지막으로, 아래의 질문들에 답해보자.\n",
    "\n",
    "1. 머신러닝을 정의한다면?\n",
    "2. 머신러닝이 도움을 줄 수 있는 문제 유형 네 가지는?\n",
    "3. 레이블된 훈련 세트란?\n",
    "4. 가장 널리 사용되는 지도 학습 작업 두 가지는?\n",
    "5. 보편적인 비지도 학습 작업 네 가지는?\n",
    "6. 사전 정보가 없는 여러 지형에서 로봇을 걸어가게 하려면 어떤 종류의 머신러닝 알고리즘을 사용할 수 있을까?\n",
    "7. 고객을 여러 그룹으로 분할하려면 어떤 알고리즘을 사용해야 할까?\n",
    "8. 스팸 감지의 문제는 지도 학습과 비지도 학습 중 어떤 문제로 볼 수 있을까?\n",
    "9. 온라인 학습 시스템이란?\n",
    "10. 외부 메모리 학습이란?\n",
    "11. 예측을 하기 위해 유사도 측정에 의존하는 학습 알고리즘은 무엇일까?\n",
    "12. 모델 파라미터와 학습 알고리즘의 하이퍼파라미터 사이에는 어떤 차이가 있을까?\n",
    "13. 모델 기반 알고리즘이 찾는 것은 무엇인가? 성공을 위해 이 알고리즘이 사용하는 가장 일반적인 전략은? 예측은 어떻게 만드는가?\n",
    "14. 머신러닝의 주요 도전 과제는?\n",
    "15. 모델이 훈련 데이터에서의 성능은 좋지만 새로운 샘플에서의 일반화 성능이 나쁘다면 어떤 문제가 있는 것인가? 가능한 해결책 세 가지는?\n",
    "16. 테스트 세트가 무엇이고 왜 사용해야 할까?\n",
    "17. 검증 세트의 목적은?\n",
    "18. 테스트 세트를 사용해 하이퍼파라미터를 튜닝하면 어떤 문제가 생길까?\n",
    "19. 교차 검증이 무엇이고, 왜 하나의 검증 세트보다 선호할까?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
