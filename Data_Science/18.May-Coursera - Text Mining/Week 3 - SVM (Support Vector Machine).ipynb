{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Before we move on,\n",
    "\n",
    "#### Classifier as a Function on input data\n",
    "\n",
    "f( documents ) -> label\n",
    "g( reviews   ) -> sentiment analysis\n",
    "\n",
    "but it's difficult to give +1 or -1 assigned to classes, and that's what SVM does.\n",
    "\n",
    "### 1) Decision Boundaries\n",
    "\n",
    "Classification function is represented by decision surfaces.\n",
    "    <br>-> **How do you find them?**\n",
    "    \n",
    "*Data overfitting\n",
    "-> Decision boundary learned over training data doesn't generalize over test data\n",
    "\n",
    "#### a. Linear Boundaries\n",
    "- Easy to find\n",
    "- Easy to evaluate\n",
    "- More generalizable : \"Occam's razor\" (Simple model generalizes better)\n",
    "\n",
    "#### b. Finding a Linear Boundary\n",
    "- Find a linear boundary = Find 'w' \n",
    "- Many methods\n",
    "    - Perceptron\n",
    "    - Linear Discriminative Analysis\n",
    "    - Linear least squares\n",
    "- Problem : Infinite number of linear boundaries ! -> What's a reasonable boundary?\n",
    " \n",
    "#### c. Maximum Margin\n",
    "- 각 클래스를 나누는 평행한 선을 두 개 구함.\n",
    "- 이 두 선의 가운데를 지나는 선을 Maximum-margin hyperplane이라고 함\n",
    "- 가운데 선부터 다른 선까지의 폭을 Margin.\n",
    "- 처음에 구한 두 개의 선을 **Support Vector**라고 부름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Support Vector Machine\n",
    "\n",
    "SVMs are **linear classifiers** that find a hyperplane to separate two classes of data : positive and negative.\n",
    "\n",
    "Given training data $(x_1, y_1), (x_2, y_2), ...; $ <br>where  $x_i = (x_1,x_2,...,x_n)$ is instance vector and $y_i$ is one of {-1, +1},<br><br>\n",
    "    -> SVM finds a linear function w (**weight vector**)<br>\n",
    "    <br>-> $f(x_i) = < w.x_i > + b $<br> if  $f(x_i) >= 0, y_i = 1; else y_i = -1 $\n",
    "\n",
    "### 1) SVM : Multi-class classification?\n",
    "SVMs work only for binary classification problems.<br>\n",
    "What about three classes?\n",
    "\n",
    "Some possible strategies :\n",
    "\n",
    "1. One vs Rest \n",
    "    - y_1 vs others\n",
    "    - y_2 vs others\n",
    "    ...\n",
    "    - y_n vs others\n",
    "    \n",
    "    **n-class SVM has n-classifiers**\n",
    "\n",
    "2. One vs One\n",
    "    - y_1 vs y_2\n",
    "    - y_2 vs y_3\n",
    "    - y_3 vs y_1\n",
    "    \n",
    "    **n-class SVM has C(n,2) classifiers**\n",
    "    \n",
    "### 2) SVM Parameters\n",
    "\n",
    "#### - Parameter C\n",
    "\n",
    "**Regularization** : How much importance should you give individual data points as compared to better generalized model?\n",
    "\n",
    " - Larger values of c = indv point is important =  *** less regularization ***\n",
    "   <br> -> Fit training data as well as possible, every data point important\n",
    " - Smaller values of c = *** more regularization ***\n",
    " <br> -> More tolerant to errors on indv points\n",
    " \n",
    "usually, the default value is 1. \n",
    "<br><br>\n",
    "#### - Other Params\n",
    "\n",
    "- Type of decision boundary : <br>\n",
    "    - Linear kernels usually work best for text data\n",
    "    - Other kernerls include ** rbf, polynomial**\n",
    "- multi_class :<br>\n",
    "    - ovr (one-vs-rest)\n",
    "    - ovo (not preferred)\n",
    "- class_weight :<br>\n",
    "    - Different classes can get different weights\n",
    "\n",
    "\n",
    "### 3) SVM Properties\n",
    "- SVM tend to be the most accurate classifiers, esp in high-dimensional data\n",
    "- Strong theoretical foundation\n",
    "- Handles only numeric features (dot-product based)\n",
    "    - Convert categorical features to numeric features\n",
    "    - Normalization\n",
    "- Hyperplane hard to interpret"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
