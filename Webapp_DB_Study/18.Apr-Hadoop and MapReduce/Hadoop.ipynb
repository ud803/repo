{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is Big Data?\n",
    "ex)\n",
    "    - All orders across 100s of stores\n",
    "    - All stock transactions for the NYSE\n",
    " \n",
    "Too big to be processed in a single machine.\n",
    "\n",
    "Big data is a loosely defined term used to describe data sets so large and complex that they become awkward to work with using standard statistical software.\n",
    "\n",
    "Challenges with big data\n",
    "    - Data is created fast\n",
    "    - Data from different sources in various formats\n",
    "\n",
    "\n",
    "3Vs ( Volume, Variety, Velocity )\n",
    "Volume\n",
    "SAN(Storage Area Networks) : expensive ! (but reliable)\n",
    "We need a cheaper way to store reliably\n",
    "Variety\n",
    "in Hadoop data format can be anything raw.\n",
    "Velocity\n",
    "\n",
    "\n",
    "Doug Cutting : Origins of Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store in HDFS (Hadoop Distributed File System)\n",
    "\n",
    "Process with MAPREDUCE\n",
    "\n",
    "The data's already on the cluster, so we can process it in place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하둡 에코시스템\n",
    "\n",
    "기본적으로 데이터를 저장하는 HDFS가 있고, MapReduce를 통해 데이터를 조작한다.\n",
    "\n",
    "하지만 이를 쉽게 해주는 PIG나 HIVE는 SQL-like query를 입력하면 자연적으로 MR로 바꾸어 데이터를 처리한다.\n",
    "\n",
    "이와 반대로 MR과 같은 단에 있는 Impala는 SQL-like query를 사용하지만, 이를 MR로 바꾸지 않고 직접적으로 HDFS에 접근한다. Low-latency query에 적합하다. 즉, 아주 빠르게 작동하고 Hive보다도 훨씬 빠르다.\n",
    "\n",
    "Hive는 길고, 큰 배치 작업에 적당하다.\n",
    "\n",
    "Sqoop은 데이터를 전통적인 관계형 데이터베이스에서 데이터를 가져와서 HDFS에 넣는다. 그리고 그 데이터를 HDFS의 다른 데이터와 함께 처리한다.\n",
    "\n",
    "Flume은 외부 시스템에서 발생한 데이터를 HDFS에 집어 넣는다.\n",
    "\n",
    "그 외에 HBse, Hue, Oozie, Mahout등 수많은 하둡 에코시스템이 있다.\n",
    "\n",
    "\n",
    "Hive enables analysis of large data sets using a language very similar to standard ANSI SQL. This means anyone who can write SQL queries can access data stored on the Hadoop cluster. This discussion introduces the functionality of Hive, as well as its various applications for data analysis and data warehousing. \n",
    "\n",
    "\n",
    "Pig is a simple-to-understand data flow language used in the analysis of large data sets. Pig scripts are automatically converted into MapReduce jobs by the Pig interpreter, so you can analyze the data in a Hadoop cluster even if you aren't familiar with MapReduce. If you want to find out more about Pig use cases, Pig's Language, Pig Latin and the benefits of utilizing Pig, you're in the right place. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./HadoopEcosystem.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서는 Cloudera 사가 만들어놓은 CDH를 통해 하둡 패키지를 설치하겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hadoop Distributed File System\n",
    "\n",
    "아래 그림처럼 하나의 파일을 여러 개의 '블럭'으로 나눈다.\n",
    "\n",
    "각 블럭은 기본 64mb의 용량이며, `blk_1` 이라는 명칭으로 부른다.\n",
    "\n",
    "그리고 각 블럭은 각 '데이터 노드(DN)'로 전송되고, '네임 노드(NN)'는 이 데이터들이 어디에 있는지 메타 데이터를 저장한다.\n",
    "\n",
    "![title](./HDFS-1.png)\n",
    "\n",
    "![title](./Hadoop-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name Node\n",
    "네임 노드가 죽으면, 모든 클러스터의 데이터도 손실되었다.\n",
    "그래서 네임 노드는 NFS(Network File System)에 백업을 해둔다.\n",
    "요즘에는 두 개의 네임 노드 (Active) (Stand By)를 두어 두 개 중 하나가 실패하더라도 동작하게 만든다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제부터는 Cloudera VMware에서 하둡을 실행한다."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "하둡 커맨드는 일반 Unix 명령어와 비슷하다.\n",
    "\n",
    "hadoop fs -ls\n",
    "    # 데이터베이스에 있는 파일 출력\n",
    "hadoop fs -put <filename> \n",
    "    # 해당 로컬 파일을 하둡 DB에 업로드\n",
    "\n",
    "hadoop fs -tail <filename>\n",
    "    # show the last few lines of a file\n",
    "    \n",
    "hadoop fs -cat <filename>\n",
    "    # show the entire file\n",
    " \n",
    "hadoop fs -mv <filename1> <filename2>\n",
    "    # rename 1 as 2\n",
    "hadoop fs -rm <filename1>\n",
    "    # Remove\n",
    "\n",
    "hadoop fs -mkdir <dir1>\n",
    "hadoop fs -put <filename1> <dir1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MapReduce\n",
    "\n",
    "하둡에서 파일은 탑다운 방식으로 읽는게 아니라, 여러 덩어리로 나뉘어져 Parallel하게 읽힘.\n",
    "\n",
    "그렇게 하지 않으면, (기존의 Hash Table 방식을 사용하면) 요즘의 데이터 양을 고려했을 때, 시간이 너무나도 많이 걸리고 메모리도 부족할 수 있다.\n",
    "\n",
    "Mapper는 값들을 \"Intermediate Records\" (key, value)로 분류\n",
    "\n",
    "Shuffle & Sort가 행해짐 (Hadoop 에서는 자동으로 이 phase를 거친다. )\n",
    "\n",
    "Reducer는 각 Key를 받음\n",
    "\n",
    "최종 결과를 Sorted하여 보려면?\n",
    "    -> 오직 한 개의 Reducer만 둔다 (효율이 안좋다)\n",
    "    -> 추가적인 단계를 거친다\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex) 만약 주어진 Key가 [Apple, Banana, Carrot, Grape]이고, 두 개의 Reducer가 있을 경우,\n",
    "각 Reducer는 어떤 Key를 받게 될까?\n",
    "   \n",
    "    1번 Reducer가 Apple과 Banana를 받게 될까?\n",
    "    그렇지 않다. 이는 알 수 없다. -> Hadoop Partitioning에 대해 알아야 한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daemons of MapReduce\n",
    "MR 작업을 수행할 때, job은 'JOB Tracker'에게 전해지고, 여기서 Mapper와 Reducer에게 일이 분배된다. \n",
    "\n",
    "그리고 실제 Mapping과 Reduce 업무는 'Task Tracker'가 전담한다.\n",
    "이는 각 노드에 software로서 존재한다.\n",
    "\n",
    "여기서 효율성이 드러나는데, 각 데이터 노드에 태스크 트래커가 있기 때문에, 노드간 데이터 전송 없이 곧바로 매핑을 할 수 있다는 점이다.\n",
    "하지만 종종 처리해야 하는 데이터가 존재하는 노드의 트래커가 바쁠 경우가 있는데, 이 때 노드 간 데이터 전송이 발생한다.\n",
    "\n",
    "그 후, Mapper는 **Intermediate Record**를 만들고, 하둡은 이를 shuffle & sort하여 Reducer에게 보내고, Reducer는 최종 결과를 HDFS로 전송한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보통 하둡은 Java로 작성되지만, **Hadoop Streaming**덕에 Python이나 다른 언어로도 가능하다.\n",
    "\n",
    "hadoop fs -ls\n",
    "hadoop fs -ls myinput \n",
    "\n",
    "위 명령어를 통해 다시 파일을 확인하자. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 다음 명령어를 실행한다\n",
    "\n",
    "hadoop jar <path to a jar> -mapper <mapper file> -reducer <reducer file> -file <mapper file> -file <reducer file> -input <input dir> -output <output dir>\n",
    "\n",
    "위 명령어가 복잡하다면 alias를 설정해도 된다.\n",
    "\n",
    "* 여기서 중요한 점은, output dir가 이미 존재하지 않아야 한다는 점이다. 하둡에서는 덮어쓰거나 하여 발생하는 사고를 막기 위해 이렇게 설하였다.\n",
    "\n",
    "일반적으로 하둡은 4개의 매퍼를 사용한다. 용량이 적을 경우, 사실 하둡은 관계형 데이터베이스보다 훨씬 효율이 떨어진다. 하지만 정말 큰 데이터셋에서 하둡의 진가가 드러난다.\n",
    "\n",
    "Output 폴더에서, SUCCESS는 성공을 의미하고, logs는 job run 도중 일어난 로그를 포함한다. part-00000는 1개의 Reducer의 결과를 의미한다.\n",
    "\n",
    "hadoop -cat part-00000 | less\n",
    "hadoop -get <filename>\n",
    "    # put과 달리 로컬 디스크로 파일을 가져온다.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MR로 할 수 있는 것은 많다.\n",
    "\n",
    "Recommendation System, Fraud Detection, Itme Classification, 등 데이터가 많고, 일이 병행될 수 있는 작업에 적합하다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
