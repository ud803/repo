{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents that Plan\n",
    "\n",
    "###### Reflex Agents\n",
    "- 현재 인지(혹은 메모리)하에서 행동을 결정한다\n",
    "- 세계의 현재 상태에 대한 기억이나 모델을 가지고 있다\n",
    "- 현재 행동의 미래 결과를 고려하지 않는다\n",
    "- 세계가 '지금' 어떤지만을 고려한다\n",
    "- 이러한 Reflex Agent가 이성적일까?\n",
    "    - 팩맨 예제 : 현재만을 보면 복잡한 경로에서 움직이지 않는다\n",
    "    \n",
    "###### Planning Agents\n",
    "- 'what if'라는 질문을 던진다\n",
    "- 행동의 결과에 기반하여 결정을 내린다\n",
    "- 세계가 행동에 반응하여 어떻게 변화는지에 대한 모델이 반드시 있어야 한다\n",
    "- 목표를 정해야 한다\n",
    "- 세계가 '어떻게 될 지'를 고려한다\n",
    "- Optimal vs. Complete Planing\n",
    "- Planning vs. Replanning\n",
    "    - Long Plan vs. short & repeated planning\n",
    " \n",
    " \n",
    "## Search Problems\n",
    "\n",
    "탐색 문제는 다음으로 구성된다 :\n",
    "- A state Space (팩맨에서 팩맨의 위치)\n",
    "- A successor function (with actions, costs, 팩맨에서 이동할 수 있는 경우)\n",
    "- A start stand and a goal test \n",
    "\n",
    "`solution`은 일련의 행동(plan)이며, 초기 상태를 목표 상태로 바꾸는 과정이다.\n",
    "\n",
    "결국 탐색 문제들은 모델을 만드는 일이다.\n",
    "\n",
    "한 지역에서 다른 지역으로 여행을 하는 예제를 살펴보자.\n",
    "- State Space : 도시\n",
    "- Successor Function : Roads : go to adjacent city with cost = distance\n",
    "- Start state : Arad\n",
    "- Goal test : Is state == \"Bucharest\"?\n",
    "- Solution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./Romania.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1. State Space\n",
    "\n",
    "`world state` : 환경(세계)에 대한 모든 세부사항을 포함한 것\n",
    "`search state` : 계획을 위해 필요한 세부사항만을 포함한다\n",
    "\n",
    "팩맨 예제에서, 서로 다른 문제를 살펴보자.\n",
    "\n",
    "- Problem : Pathing\n",
    "    - States : (x,y) location\n",
    "    - Action : NSEW (방향)\n",
    "    - Successor : update location\n",
    "    - Goal test : is (x,y ) = END\n",
    "<br>\n",
    "- Problem : Eat-All-Dots\n",
    "    - States : (x,y), dot booleans\n",
    "    - Actions : NSEW (방향)\n",
    "    - Successor : update location / dot boolean\n",
    "    - Goal test : dots all false (ate all the dots)\n",
    " <br>\n",
    "- Calculating World State\n",
    "    - Agent positions : 120\n",
    "    - Food count : 30\n",
    "    - Ghost positions : 12\n",
    "    - Agent facing : NSEW\n",
    "    - World States? : 120*2^30 * 12^2 * 4\n",
    "    - Search States for pathing? : 120 (abstracted)\n",
    "    - Search States for eat-all-dots? : 120*2^30\n",
    "    - 일반적인 팩맨에서 state space에 포함되어야 할 것들\n",
    "        - agent position\n",
    "        - dot booleans\n",
    "        - power pellet booleans\n",
    "        - remaining scared time\n",
    "        - Walls? -> wall은 Successor에서 포함된다. 따라서 state에는 포함하지 않는다\n",
    "        - ghost도 포함하지 않는다\n",
    "        \n",
    "        \n",
    "**State Space Graph**는 이러한 탐색 문제를 수학적 도식으로 표현해준다.\n",
    "- 각 노드는 세계의 축약본이다\n",
    "- 아크는 successor (action result)를 표현한다\n",
    "- 각 State는 오직 한 번만 일어난다\n",
    "- 하지만 이러한 그림을 메모리에 그리는 것은 너무도 복잡하다 (따라서 잘 그리지 않는다)\n",
    "\n",
    "**Search Tree**는 :\n",
    "- 계획과 결과에 대한 'what if' 트리이다\n",
    "- 초기 상태가 뿌리 노드이다\n",
    "- 자식 노드가 successor가 된다\n",
    "- 노드는 상태를 보여주지만, 그러한 상태를 얻게된 '계획'에 대응한다\n",
    "- 대부분의 문제에서, 전체 트리를 그릴 수는 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./StateSpace.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Search Tree**에서 중요한 것은 :\n",
    "- 잠재적인 계획에 대해서만 뻗어 나간다\n",
    "- 뻗어간 계획의 분파(fringe)를 유지한다\n",
    "- 가능한 최소한의 노드만을 연장한다"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# General Tree Search Pseudo code\n",
    "\n",
    "funcion Tree-search(problem, strategy) returns a solution, or failure :\n",
    "    \n",
    "    initialize the search tree using the initial state of problem\n",
    "    loop do :\n",
    "        if there are no candidates for expansion then return failure\n",
    "        choose a leaf node for expansion according to strategy\n",
    "        if the node contains a goal state then return the corresponding solution\n",
    "        else expand the node and add the resulting nodes to the search tree\n",
    "    end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 그림에서 왼쪽이 **서치트리**이고, 오른쪽이 해당하는 **fringe**이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./fringe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Depth-First Search (DFS)\n",
    "\n",
    "**Depth-First-Search 깊이우선탐색**은 탐색트리 문제를 해결하는 한 방법 중 하나이다.\n",
    "\n",
    "- Strategy : 가장 깊은 노드 먼저 뻗어나간다\n",
    "- Implementation : 프린지는 LIFO 스택 구조이다\n",
    "\n",
    "###### Properties\n",
    "\n",
    "- Complete : 솔루션을 반드시 찾을 수 있는가?\n",
    "- Optimal : 최소 비용 경로를 반드시 찾을 수 있는가?\n",
    "- 시간 복잡도?\n",
    "- 공간 복잡도?\n",
    "- 노드의 총 개수?(자식노드가 b개씩 있을 경우) = $1 + b + b^2 + ... + b^m = O(b^m)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./dfsproperty.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "빨간색이 목표하는 노드이다.\n",
    "\n",
    "**그럼 위 그림에서 DFS는 어떤 노드로 뻗어나갈까?**\n",
    "- 트리의 왼쪽부터 돈다\n",
    "- 전체 트리를 거칠 수도 있다 (goal state가 오른쪽 꼭지점에 있을 때)\n",
    "- m이 무한하다면, $O(b^m)$의 시간이 걸린다.\n",
    "\n",
    "**그럼 Fringe는 메모리에 얼마나 많은 공간을 차지할까?**\n",
    "- $O(b*m)$\n",
    "\n",
    "**완전한(Complete) 탐색 방법일까?**\n",
    "- m이 무한대가 될 수 있다. 따라서 무한 사이클만 방지한다면 가능하다\n",
    "\n",
    "**최적의(Optimal) 탐색 방법일까?**\n",
    "- 그렇지 않다. 이 방법은 \"가장 왼쪽의\" 결과만을 찾는다. (깊이나 비용에 관계없이)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Breadth-First Search (BFS)\n",
    "**Breadth-First Search 너비우선탐색**은 또 다른 방법이다.\n",
    "\n",
    "BFS는 가장 얕은 경로를 먼저 탐색한다.\n",
    "- Strategy : 가장 얕은 노드 먼저 탐색한다\n",
    "- Implementation : 프린지는 FIFO 큐의 형태이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./bfs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Properties\n",
    "\n",
    "**위 그림에서 BFS는 어떤 노드로 뻗어나갈까?**\n",
    "- 가장 얕은 goal state 위의 모든 노드를 거친다 (Layer by Layer!)\n",
    "- $O(b^s)$의 시간이 걸린다\n",
    "\n",
    "** 프린지가 메모리에 얼마나 많은 공간을 차지할까?**\n",
    "- $O(b^s)$\n",
    "\n",
    "** 완전한가?(Complete) **\n",
    "- s가 유한하기만 하다면 완전하다\n",
    "\n",
    "** 최적의 방법인가?(Optimal) **\n",
    "- 비용이 모두 1인 경우에만 그렇다 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BFS vs DFS\n",
    "\n",
    "- BFS가 DFS보다 좋을 때는?\n",
    "    - 목표값들의 깊이가 매우 클 때\n",
    "    \n",
    " \n",
    "- DFS가 BFS보다 좋을 때는?\n",
    "    - 목표값들이 모두 동등한 깊이에 매우 깊게 있을 때\n",
    "    - BFS는 보통 메모리가 아주 많이 든다\n",
    "    \n",
    "\n",
    "### Iterative Deepening\n",
    "- 아이디어 : BFS의 시간적 장점과 DFS의 공간적 장점을 함께 사용하는 것\n",
    "- DFS를 깊이 1로 실행한다.\n",
    "- 만약 목표값이 없으면, 깊이 2로 실행한다.\n",
    "- ...\n",
    "- 목표값을 찾는다.\n",
    "\n",
    "\n",
    "### 3. Cost Sensitive Search - Uniform Cost Search\n",
    "\n",
    "BFS는 행동의 수의 관점에서 가장 짧은 경로를 찾는 것이다.\n",
    "따라서 비용이 최소인 경로를 찾지는 않는다. \n",
    "\n",
    "- strategy : 가장 비용이 낮은 노드를 먼저 탐색한다\n",
    "- 프린지는 priority 큐이다. (priority : cumulative cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The One Queue\n",
    "이 모든 탐색 알고리즘들은 프린지 전략을 제외하고는 모두 같다.\n",
    "\n",
    "- 개념적으로, 모든 프린지는 **우선순위 큐**이다. (collections of nodes with attached priorities)\n",
    "- 실제로, DFS와 BFS에서, 스택과 큐를 사용하여 log(n) 의 오버헤드를 무시할 수 있다.\n",
    "- 다양한 큐 오브젝트를 갖는 하나의 코드를 짤 수도 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
