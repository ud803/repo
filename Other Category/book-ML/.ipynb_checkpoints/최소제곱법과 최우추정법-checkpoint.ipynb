{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최소제곱법\n",
    "\n",
    "어떤 관측점 `x`를 새로 관측했을 때, 이미 추측한 함수를 사용하여 이 `x`에 관한 관측값 `t`가 얼마 만큼이 되는지를 추정해보자.\n",
    "\n",
    "즉, `x`가 주어졌을 때 이에 대응하는 `t`값을 추정하는 것이 목적이다. 통계학에서는 `x`를 **설명 변수**라고 부르고, `t`를 **목적 변수**라고 부른다.\n",
    "\n",
    "한편 머신러닝에서는 `x`가 분석 대상의 성질을 특징 짓는 변수라고 여겨 **특징 변수**라고 부른다. 여러 개의 특징 변수를 합쳐 벡터값을 만들어서 다루는 것이 일반적이기 때문에, 이 벡터를 **특징 벡터**라고 부른다.\n",
    "\n",
    "미래에 발생할 일을 예측하기 위해서는 예측에 적합한 데이터를 사용해야 하고, 데이터 과학자는 직접 자신이 어떤 데이터를 특징 변수로 사용할지 결정해야 한다.\n",
    "\n",
    "\n",
    "### 1. 다항식 근사와 오차함수 설정\n",
    "\n",
    "먼저 `x`에 대한 다항식을 다음과 같이 설정해보자.\n",
    "\n",
    "$$ f(x) = w_0 + w_1x + w_2x^2 + ... + w_Mx^M $$\n",
    "<br>\n",
    "$$ = \\sum_{m=0}^Mw_mx^m $$\n",
    "\n",
    "<br>\n",
    "여기서, 주어진 값 $x_1$에서 $x_10$까지 위 식으로 계산되는 t값과 실제 관측된 값 $t_n$을 비교한다.\n",
    "\n",
    "이를 **오차**라고 정의하고, 아래와 같이 쓴다.\n",
    "\n",
    "$$ \\{f(x_1)-t_1\\}^2 + \\{f(x_2)-t_2\\}^2 + ... + \\{f(x_{10})- t_{10}\\}^2 $$\n",
    "\n",
    "이제 간단히 계산할 수 있도록, 위 식을 반으로 나누고, N개의 관측점에 대해 일반화를 시키면 아래와 같이 오차를 표현할 수 있다.\n",
    "\n",
    "$$ E_D = \\frac{1}{2}\\sum_{n=1}^N \\{f(x_n)-t_n\\}^2$$\n",
    "\n",
    "그리고 위 식에 실제 다항식을 대입해보면, 아래와 같은 식을 얻는다.\n",
    "\n",
    "$$ E_D = \\frac{1}{2}\\sum_{n=1}^N(\\sum_{m=0}^Mw_mx_n^m-t_n)^2 $$\n",
    "\n",
    "결국 이 식의 값인 $E_D$를 최소로 만드는 것이 최종 목표가 된다. 이 형태로 계산되는 오차를 **오차의 제곱**이라고 부르는데, 여기서 ***오차의 제곱을 최소화***할 수 있는 답을 구하려고 하는 것이므로 이 기법을 **최소제곱법**이라고 부른다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./Materials/Image/Figure_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. 오차함수를 최소화할 수 있는 조건\n",
    "\n",
    "여기서는 행렬의 풀이 (헤세 행렬)을 통해 풀이한다.\n",
    "\n",
    "아직 거기까지 이해하지 못하므로 패스한다. 나중에 더 알아보자.\n",
    "\n",
    "주어진 스크립트는 이 과정을 모두 구현해두었다.\n",
    "\n",
    "M=0 ~ M=9 일 때까지 각 항의 계수가 나온다. 그래프에서 빨간색 실선이 우리가 추정한 값들이다. \n",
    "\n",
    "M이 커질수록 차수가 높아져 M = 0일 때는 수평인 직선, M = 1일 때는 일차식, 그리고 점점 다항식으로 가는 것을 알 수 있다.\n",
    "\n",
    "*하지만 단순히 그래프만을 보고 판단할 수는 없다. 나중에 적절한 차수 값을 찾아내는 방법을 더 공부할 것이다.*\n",
    "\n",
    "##### 평균 제곱근 오차(Root Mean Square Error)\n",
    "그리고 이 때, `E(RMS)`라는 값을 사용하는데 이는 기존 $E_D$에서 조금 수정된 값이고, 이는 *우리가 다항식을 통해 예상할 수 있는 값과 트레이닝 셋 값들이 평균에서 어느정도 떨어져 있는지를 알려준다.*\n",
    "\n",
    "$$ E(RMS) = \\sqrt{\\frac{2E_D}{N}} $$ \n",
    "\n",
    "\n",
    "M=0인 경우, E(RMS) =0.77로 각 값들이 평균적으로 0.77만큼 떨어져 있다는 것을 의미한다. 이는 차수가 높아질수록 줄어들다가 M=9에서 0이 되는데, 생각해보면 당연한 결과이다.\n",
    "\n",
    "왜냐하면 M=9일 경우 $w_0 - w_9$까지 총 10개의 항을 갖게 된다. 이 10개 항으로 총 데이터(10개)를 각각 대응할 수 있으므로, 우리가 추정하고자 하는 식은 완벽히 재현된다.\n",
    "\n",
    "만약 $M \\geq 10$이라면 무수히 많은 해가 존재해서 애초에 방정식을 풀 수가 없다.\n",
    "\n",
    "일반적으로 $ M+1 \\gt N$ 으로 확대하여 생각하면 된다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 통계모델이라는 관점에서 최소제곱법이란\n",
    "\n",
    "앞서 트레이닝 셋에 최소제곱법을 적용하여 목적변수 t를 예측하기 위한 다항식을 결정했다.\n",
    "\n",
    "**통계모델**이란 '어떤 현상에 관하여 통계학적인 기법을 사용하여 그 현상을 설명하는 것 혹은 에측할 모델을 만들어 내는 것'이라고 말할 수 있다.\n",
    "\n",
    "여기서 말하는 파라메트릭 모델(모수형)에서는 아래 3단계를 거쳐 모델, 즉 수식을 결정한다.\n",
    "\n",
    "##### (1) 파라미터를 포함한 모델(수식)을 설정한다.\n",
    "\n",
    "그런데 현상을 설명할 모델이란 것은 갑자기 나오는 게 아니고 맨 처음 어떠한 가정을 해놓고 그 형태를 대강 정해 놓는다.\n",
    "\n",
    "앞선 최소제곱법에서는 t를 예측하는 수식으로 M차 다항식을 가정했고, 이때 다항식의 계수가 파라미터가 된다. 즉, 이 파라미터를 변경해가면서 모델을 튜닝해가는 단계이다.\n",
    "\n",
    "##### (2) 파라미터를 평가할 기준을 정한다.\n",
    "\n",
    "현상을 설명할 수식은 여러가지가 있지만, 그 모두를 검토할 수는 없으므로 가장 적합한 것을 골라낸다. M=1인 경우에서 차수가 증가하게 되면, 2차원 평면을 벗어나 고차원 평면으로 파라미터의 가능한 영역이 증가한다.\n",
    "\n",
    "그렇다면 여기서 어떤 파라미터가 좋은 녀석인지 구분할 수 있을까? \n",
    "<br>최소제곱법에서는 *오차의 제곱 $E_D$*가 그 역할을 한다.\n",
    "\n",
    "사실 파라미터를 판단하는 기준을 설정하는 데에도 자유도가 존재하는데, 만약 오차의 제곱 $E_D$ 대신 다른 기준을 적용시켰을 때 다른 결과를 얻을 수도 있기 때문이다.\n",
    "\n",
    "***이때 어느 쪽 기준이 좋을지 판단하는 일은 어려운 문제이고, 계속 공부하면서 알아가야 한다.***\n",
    "\n",
    "##### (3) 가장 적합하다고 평가할 수 있는 파라미터를 결정한다.\n",
    "판단 기준이 설정됐다면 이 기준에 따라 최적의 파라미터 값을 찾는다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4. 오버 피팅 검출\n",
    "\n",
    "다시 최적의 차수 M에 대해 생각해보자. 이 내용을 이해하기 위해서는 '머신러닝을 이용하는 목적'에 대해 다시 한 번 생각할 필요가 있다.\n",
    "\n",
    "머신러닝이라는 것은 주어진 트레이닝 셋 데이터를 가지고 최적의 파라미터를 결정하는 것 이상의 의미는 없다. 데이터 과학자에게 중요한 것은 이 결과가 *'미래를 예측하는 데'* 도움이 되는지 되지 않는지이다. \n",
    "\n",
    "##### (1) 트레이닝 셋과 테스트 셋\n",
    "\n",
    "앞서 살펴본 대로 차수를 높이면 트레이닝 셋을 훨씬 정확하게 재현할 수 있다.\n",
    "\n",
    "그러나 트레이닝 셋의 데이터는 '우연에 의해 얻어진 값'이며 새 데이터를 얻었을 때도 동일한 값은 아닐 것이다.\n",
    "\n",
    "아래 그래프는 M을 0~9로 변경해 갔을때 RMS가 어떻게 변화하는지를 보여주는 그래프이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./Materials/Image/Figure_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "트레이닝 셋에서는 꾸준히 RMS가 감소하지만, 테스트 셋에서는 M=4를 넘어가면 예측력은 그 이상 커지지 않는 것을 알 수 있다.\n",
    "\n",
    "이렇게 미지의 데이터를 예측하는 능력을 **모델의 일반화 능력**이라고 부른다. 이 예제에서도 트레이닝 셋만이 갖는 특징에 맞춰 과잉으로 튜닝이 가해졌기 때문에 **오버피팅(과적합)**이 발생하는 것이다.\n",
    "\n",
    "##### (2) 교차 검증을 통한 일반화\n",
    "\n",
    "머신러닝을 위해 수집한 귀중한 데이터를 낭비 없이 이용하면서 적절한 검증을 실시하려면 어떻게 해야 할까?\n",
    "\n",
    "이때 이용되는 것이 바로 [**교차 검증 기법(Cross Validation)**](https://en.wikipedia.org/wiki/Cross-validation_(statistics%29) 이다.\n",
    "\n",
    "한 데이터를 여러 조각으로 균등하게 나눈 후, 하나를 제외한 데이터로 트레이닝하여 남은 조각으로 테스트를 진행한다.\n",
    "\n",
    "이는 조각의 수가 N개라면 N번 검증을 할 수 있다. 이 결과들을 토대로 오버 피팅이 발생하지 않는 최적의 차수 M을 결정한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 데이터의 개수에 따른 오버피팅의 변화\n",
    "\n",
    "트레이닝 데이터가 10개이므로 파라미터의 개수가 10개 이상이면 모든 데이터를 정확하게 재현할 수 있다. 따라서 RMS가 0이 되었다.\n",
    "\n",
    "역으로 이야기하면 *데이터 개수가 충분히 많다면 다항식의 차수가 커져도 모든 데이터를 재현할 수 없고 오버 피팅은 그다지 발생하지 않게 된다*고 볼 수 있다.\n",
    "\n",
    "같은 예제를 N=100으로 설정하여 살펴보자.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./Materials/Image/Figure_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 그림을 보면 다항식의 차수를 높여도 그래프의 모양이 크게 왜곡되지 않고 M=3일 때와 M=9일 때 RMS 값이 0.28로 비슷한 것을 알 수 있다.\n",
    "\n",
    "또한 아래 그래프를 보면, 트레이닝과 테스트 셋 모두에서 RMS가 0.3 정도에서 변화지 않는 것을 확인할 수 있다.\n",
    "\n",
    "즉, *M=3보다 차수를 높여도 모델의 일반화 능력은 향상되지 않는다는 말이다*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./Materials/Image/Figure_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 개수와 오버 피팅의 일반적인 관계에 대하여 말해볼 수 있다.\n",
    "\n",
    "**데이터 개수가 적을 경우 분석 대상의 본질적인 특징보다는 취득한 데이터가 우연히 가지고 있는 특징이 더 눈에 띄게 된다. 이는 오버피팅의 성질이다.**\n",
    "\n",
    "**반대로 데이터 개수가 많으면 그만큼 본질적인 특징을 알아보기 쉬워진다.**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
