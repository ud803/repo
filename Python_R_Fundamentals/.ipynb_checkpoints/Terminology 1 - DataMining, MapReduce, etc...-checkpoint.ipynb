{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. MapReduce\n",
    "\n",
    "1. It is a programming model and an associated implementation for processing and generating big data sets with a parallel, distributed algorithm on a cluster.\n",
    "\n",
    "2. The term actually refers to two separate and distinct tasks that Hadoop program perform. MapReduce allows for massive scalability across hundreds or thousands of servers in a Hadoop cluster. \n",
    "\n",
    "3. The system orchestrates the processing by *marshalling the distributed servers, running the various tasks in parallel, managing all communications and data transfers between the various part of the system.\n",
    "\n",
    "\n",
    "\n",
    "**Marshalling : process of transforming the memory representation of an object to a data format suitable for storage of transmission, and it is typically used when data must be moved between different parts of a computer program or from one program to another.*\n",
    "\n",
    "**Fault tolerance : it is the property that enables a system to continue operating properly in the event of the failure of some of its components.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) MapReduce Process\n",
    "\n",
    "### a. \"Map\" Step\n",
    "It takes a set of data and converts it into another set of data, where individual elements are broken down into tuples (key/value pairs)\n",
    "\n",
    "Each worker node applies the \"map()\" function to the local data, and writes the output to a temporary storage. A master node ensures that only one copy of redundant input data is processed.\n",
    "\n",
    "### b. \"Shuffle\" Step\n",
    "Worker nodes redistribute data based on the output keys (produced by the \"map()\" function), such that all data belonging to one key is located on the same worker node.\n",
    "\n",
    "### c. \"Reduce\" Step\n",
    "It takes the output from a map as input and combines those data tuples into a smaller set of tuples. \n",
    "\n",
    "Worker nodes now process each group of output data, per key, in parallel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Mining\n",
    "\n",
    "Data Mining is the computing process of **discovering patterns in large data sets involviing methods at the intersection of machine learning, statistics, and database systems. **\n",
    "\n",
    "## 1) What it is\n",
    "- It is an essential process where intelligent methods are applied to extract data patterns.\n",
    "- It is an interdisciplinary subfield of computer science.\n",
    "- The overall goal of the data mining process is to extract information from a data set and transform it into an understandable structure for further use.\n",
    "- Aside from the raw analysis step, ** it involves database and data management aspects, data pre-processing, model and inference considerations, interestingness metrics, complexity considerations, post-processing of discovered structures, visualization, and online udating. **\n",
    "- Data mining is the analysis step of the “knowledge discovery in databases” process, or KDD.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The term is a *misnomer* because the goal is the extraction of patterns and knowledge from large amounts of data, not the extraction of data itself.\n",
    "\n",
    "Neither the data collection, data preparation, nor result interpretation and reporting is part of the data mining step, but do belong to the overall *KDD process as additional steps.\n",
    "<br><br>\n",
    "\n",
    "***KDD Process**\n",
    "The knowledge discovery in databases (KDD) process ;\n",
    "1. Selection\n",
    "2. Pre-Processing\n",
    "3. Transformation\n",
    "4. Data Mining\n",
    "5. Interpretation / evaluation\n",
    "\n",
    "Or\n",
    "\n",
    "1. Business understanding\n",
    "2. Data understanding\n",
    "3. Data preparation\n",
    "4. Modeling\n",
    "5. Evaluation\n",
    "6. Deployment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Actual tasks\n",
    "\n",
    "### a. Pre-Processing\n",
    "- A target data set must be assembled. \n",
    "- As data mining can only uncover patterns actually present in the data, the target data set must be large enough to contain these patterns while remaining concise enough to be mined within an acceptable time limit.\n",
    "\n",
    "- A common source for data is a data mart or data warehouse. The target is then cleaned. Data cleaning removes the observations containing noise and those with missing data.\n",
    "\n",
    "\n",
    "### b. Data mining - six common classes of tasks\n",
    "The actual data mining task is the semi-automatic or automatic analysis of large quantities of data to extract previously unknown, interesting patterns such as\n",
    "\n",
    "- *** Anomaly Detection (outlier/change/deviation detection) ***\n",
    "  \n",
    "  The identification of unusual data records, that might be interesting or data errors that require further investigation.<br><br>\n",
    "-  ***Association rule learning (dependency modeling) ***\n",
    "    \n",
    "    Searches for relationships between variables. For example, a supermarket might gather data on customer purchasing habits. <br><br>\n",
    "- ***Clustering***\n",
    "    \n",
    "    is the task of discovering groups and structures in the data that are in some way or another “similar”, without using known structures in the data.<br><br>\n",
    "- ***Classification***\n",
    "    \n",
    "    is the task of generalizing known structure to apply to new data. For example, an e-mail program might attempt to classify an e-mail as “legitimate” or as “spam”.<br><br>\n",
    "- ***Regression***\n",
    "    \n",
    "    attempts to find a function which models the data with the least error that is, for estimating the relationships among data or datasets.<br><br>\n",
    "- ***Summarization***\n",
    "    \n",
    "    providing a more compact representation of the data set, including visualization and report generation<br><br>\n",
    "\n",
    "\n",
    "These usually involve using database techniques such as *spatial indices. \n",
    "\n",
    "\n",
    "### c. Results Validation\n",
    "Data mining can unintentionally be misused, and can then produce results which appear to be significant; but which do not actually predict future behaviour and cannot be reproduced on a new sample of data and bear little use. \n",
    "\n",
    "Often this results from investigating too many hypotheses and not performing proper statistical hypothesis testing. A simple version of this problem in ML is known as overfitting.\n",
    "\n",
    "Not all patterns found by the data mining algorithms are necessarily valid. It is common for the data mining algorithms to find patterns in the training set which are not present in the general data set. This is called overfitting. To overcome this, the evaluation uses a test / train set split.\n",
    "\n",
    "A number of statistical methods may be used to evaluate the algorithms, such as *ROC curves.\n",
    "\n",
    "<br><br>\n",
    "*** Spatial Database **\n",
    "\n",
    "A spatial database is a database that is **optimized for storing and querying data that represents objects defined in a geometric space.** \n",
    "\n",
    "Most spatial DB allow representing simple geometric objects such as points, lines, and polygons. Some spatial databases handle more complex structures such as 3D objects, topological coverages, linear networks, and TINs.\n",
    "\n",
    "And Spatial DBs can perform a wide variety of spatial operations. \n",
    "\n",
    "Spatial Indices are used by spatial DBs to optimize spatial queries. Conventional index types do not efficiently handle spatial queries such as how far two points differ.\n",
    "\n",
    "\n",
    "*** ROC Curve **\n",
    "(Cont)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
